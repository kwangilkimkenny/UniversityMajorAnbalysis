{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import docx2txt\n",
    "import sys\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docx 문서들을 불러와서 txt 로 변환한다.\n",
    "txtdata = docx2txt.process(\"UniversityMajor/01_Harvard/HarvardCS40COMMUNITY-03.docx\") \n",
    "with open(\"UniversityMajor/01_Harvard/HarvardEssays.txt\", \"w\", encoding='UTF8') as text_file:\n",
    "    print(txtdata, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /anaconda3/lib/python3.6/site-packages (3.4)\r\n",
      "Requirement already satisfied: six in /Users/kimkwangil/.local/lib/python3.6/site-packages (from nltk) (1.14.0)\r\n",
      "Requirement already satisfied: singledispatch in /anaconda3/lib/python3.6/site-packages (from nltk) (3.4.0.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kimkwangil/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "tags = nltk.pos_tag(txtdata.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Statistical', 'JJ'),\n",
       " ('Physics', 'NNPS'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('comedy', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('long-shot.', 'NN'),\n",
       " ('Professor', 'NNP'),\n",
       " ('Nir', 'NNP'),\n",
       " ('Gov’s', 'NNP'),\n",
       " ('lecture', 'NN'),\n",
       " ('(held', 'NN'),\n",
       " ('during', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('summer', 'NN'),\n",
       " ('camp', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Weizmann', 'NNP'),\n",
       " ('Institute', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Science,', 'NNP'),\n",
       " ('Israel)', 'NNP'),\n",
       " ('covered', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('single', 'JJ'),\n",
       " ('topic', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('physics.', 'JJ'),\n",
       " ('However,', 'NNP'),\n",
       " ('its', 'PRP$'),\n",
       " ('application', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('truly', 'RB'),\n",
       " ('versatile—from', 'JJ'),\n",
       " ('cell', 'NN'),\n",
       " ('dynamics', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('collaboration', 'NN'),\n",
       " ('patterns', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('ants.', 'JJ'),\n",
       " ('Full', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('curiosity,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('approached', 'VBD'),\n",
       " ('him', 'PRP'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lecture', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('asked', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('learn', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('magical', 'JJ'),\n",
       " ('tool', 'NN'),\n",
       " ('known', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('Statistical', 'JJ'),\n",
       " ('Physics.', 'NNP'),\n",
       " ('“Start', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('ensemble', 'JJ'),\n",
       " ('theory,”', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('advised.', 'VBZ'),\n",
       " ('Though,', 'NNP'),\n",
       " ('Statistical', 'NNP'),\n",
       " ('Physics', 'NNP'),\n",
       " ('seemed', 'VBD'),\n",
       " ('more', 'JJR'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('tragedy,', 'NN'),\n",
       " ('seen', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('close-up.', 'JJ'),\n",
       " ('Spending', 'NN'),\n",
       " ('weeks', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('several', 'JJ'),\n",
       " ('textbooks,', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " ('found', 'VBD'),\n",
       " ('myself', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('maze.', 'NN'),\n",
       " ('To', 'TO'),\n",
       " ('understand', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('system,', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('shall', 'MD'),\n",
       " ('calculate', 'VB'),\n",
       " ('every', 'DT'),\n",
       " ('component’s', 'NN'),\n",
       " ('behavior.', 'NN'),\n",
       " ('This', 'DT'),\n",
       " ('commandment', 'NN'),\n",
       " ('summarizes', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('physics', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('learned', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('Korea', 'NNP'),\n",
       " ('Science', 'NNP'),\n",
       " ('Academy', 'NNP'),\n",
       " ('(KSA).', 'NNP'),\n",
       " ('However,', 'NNP'),\n",
       " ('when', 'WRB'),\n",
       " ('we', 'PRP'),\n",
       " ('consider', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('system', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('myriad', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('particles,', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('directive', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('defied', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('virtual', 'JJ'),\n",
       " ('impossibility', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('figuring', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('motions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('particle.', 'NN'),\n",
       " ('Instead,', 'NNP'),\n",
       " ('physicists', 'VBZ'),\n",
       " ('construct', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('ensemble', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('macroscopic', 'NN'),\n",
       " ('snapshots', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('system.', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('snapshots', 'NNS'),\n",
       " ('contain', 'VBP'),\n",
       " ('different', 'JJ'),\n",
       " ('particle', 'NN'),\n",
       " ('arrangements', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('movements', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('“collection.”', 'NN'),\n",
       " ('As', 'RB'),\n",
       " ('far', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('understood,', 'VBP'),\n",
       " ('ensemble', 'JJ'),\n",
       " ('theory', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('similar', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('understanding', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('theme', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('watching', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('preview', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('only', 'RB'),\n",
       " ('consists', 'VBZ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('important', 'JJ'),\n",
       " ('scenes.', 'NN'),\n",
       " ('Hypothetically,', 'NNP'),\n",
       " ('if', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('analyze', 'VB'),\n",
       " ('every', 'DT'),\n",
       " ('actor,', 'NN'),\n",
       " ('every', 'DT'),\n",
       " ('line,', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('every', 'DT'),\n",
       " ('frame,', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('actually', 'RB'),\n",
       " ('hinder', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('from', 'IN'),\n",
       " ('grasping', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('overall', 'JJ'),\n",
       " ('message', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('film.', 'NN'),\n",
       " ('In', 'IN'),\n",
       " ('short,', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('theory', 'NN'),\n",
       " ('states', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('state', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('matter', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('understood', 'VBN'),\n",
       " ('without', 'IN'),\n",
       " ('knowing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('movements', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('each', 'DT'),\n",
       " ('and', 'CC'),\n",
       " ('every', 'DT'),\n",
       " ('particle.', 'NN'),\n",
       " ('At', 'IN'),\n",
       " ('odds', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('existing', 'VBG'),\n",
       " ('beliefs,', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('approach', 'NN'),\n",
       " ('refused', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('settle', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('brain.', 'NN'),\n",
       " ('Even', 'RB'),\n",
       " ('well-designed', 'JJ'),\n",
       " ('exercise', 'NN'),\n",
       " ('problems', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('textbooks', 'NNS'),\n",
       " ('could', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('save', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('from', 'IN'),\n",
       " ('drowning', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('confusion.', 'NN'),\n",
       " ('Meanwhile,', 'NNP'),\n",
       " ('ensemble', 'JJ'),\n",
       " ('theory', 'NN'),\n",
       " ('suggested', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('possible', 'JJ'),\n",
       " ('explanation', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('unanswered', 'JJ'),\n",
       " ('questions', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('leadership', 'NN'),\n",
       " ('during', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('KSA', 'NNP'),\n",
       " ('Science', 'NNP'),\n",
       " ('Fair.', 'NNP'),\n",
       " ('To', 'TO'),\n",
       " ('successfully', 'RB'),\n",
       " ('manage', 'VB'),\n",
       " ('KSA’s', 'NNP'),\n",
       " ('largest', 'JJS'),\n",
       " ('international', 'JJ'),\n",
       " ('festival,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('provided', 'VBD'),\n",
       " ('detailed', 'JJ'),\n",
       " ('instructions', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('each', 'DT'),\n",
       " ('volunteer.', 'NN'),\n",
       " ('For', 'IN'),\n",
       " ('example,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('assigned', 'VBD'),\n",
       " ('each', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('fifteen', 'JJ'),\n",
       " ('volunteers', 'NNS'),\n",
       " ('a', 'DT'),\n",
       " ('specific', 'JJ'),\n",
       " ('task,', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('placement', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('posters', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('strict', 'JJ'),\n",
       " ('discussion', 'NN'),\n",
       " ('guidelines', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('sessions,', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('start', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('presentation.', 'NN'),\n",
       " ('Despite', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('efforts', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('control', 'VB'),\n",
       " ('all', 'DT'),\n",
       " ('aspects,', 'VB'),\n",
       " ('some', 'DT'),\n",
       " ('problems', 'NNS'),\n",
       " ('emerged', 'VBD'),\n",
       " ('as', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('volunteers', 'NNS'),\n",
       " ('starting', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('miss', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('detailed', 'JJ'),\n",
       " ('plan', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('action.', 'JJ'),\n",
       " ('Initially,', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('clueless', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('tried', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('understand', 'VB'),\n",
       " ('how', 'WRB'),\n",
       " ('such', 'JJ'),\n",
       " ('a', 'DT'),\n",
       " ('detailed', 'JJ'),\n",
       " ('plan', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('execution', 'NN'),\n",
       " ('could', 'MD'),\n",
       " ('go', 'VB'),\n",
       " ('haywire;', 'RB'),\n",
       " ('however,', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('knowledge', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('ensemble', 'JJ'),\n",
       " ('theory', 'NN'),\n",
       " ('deepened,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('began', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('realize', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('fundamental', 'JJ'),\n",
       " ('problems', 'NNS'),\n",
       " ('rooted', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('approach.', 'JJ'),\n",
       " ('Instead', 'RB'),\n",
       " ('of', 'IN'),\n",
       " ('micromanagement,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('should', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('viewed', 'VBN'),\n",
       " ('KSASF', 'NNP'),\n",
       " ('as', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('ensemble', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('seen', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('bigger', 'JJR'),\n",
       " ('picture', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('KSASF.', 'NNP'),\n",
       " ('As', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('head', 'NN'),\n",
       " ('volunteer,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('should', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('brave', 'VBN'),\n",
       " ('enough', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('step', 'NN'),\n",
       " ('back,', 'NN'),\n",
       " ('observe,', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('created', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('macroscopic', 'NN'),\n",
       " ('background', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('honors', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('core', 'NN'),\n",
       " ('essence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('KSASF—the', 'NNP'),\n",
       " ('exchange', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('scientific', 'JJ'),\n",
       " ('ideas.', 'NN'),\n",
       " ('Given', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('second', 'JJ'),\n",
       " ('chance', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('head', 'JJ'),\n",
       " ('volunteer', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('KSA', 'NNP'),\n",
       " ('Youth', 'NNP'),\n",
       " ('Science', 'NNP'),\n",
       " ('Camp,', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('mentoring', 'JJ'),\n",
       " ('event', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('sixty', 'NN'),\n",
       " ('elementary', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('middle', 'JJ'),\n",
       " ('school', 'NN'),\n",
       " ('students,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('envisioned', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('camp’s', 'NN'),\n",
       " ('activities', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('perspective', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('ensemble,', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('each', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('camp', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('align', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('camp’s', 'NN'),\n",
       " ('core', 'NN'),\n",
       " ('message—learning', 'VBG'),\n",
       " ('science', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('inquiries.', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('designed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('events', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('macroscopic', 'NN'),\n",
       " ('thinking:', 'NN'),\n",
       " ('being', 'VBG'),\n",
       " ('relevant', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('given', 'VBN'),\n",
       " ('theme', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('minimizing', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('structure', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('guidelines.', 'NN'),\n",
       " ('This', 'DT'),\n",
       " ('encouraged', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('volunteers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('proactive,', 'JJ'),\n",
       " ('fully', 'RB'),\n",
       " ('showing', 'VBG'),\n",
       " ('their', 'PRP$'),\n",
       " ('expertise', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('dynamic', 'JJ'),\n",
       " ('‘open', 'JJ'),\n",
       " ('discussion', 'NN'),\n",
       " ('sessions.’', 'NN'),\n",
       " ('Compared', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('KSASF,', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('camp', 'NN'),\n",
       " ('became', 'VBD'),\n",
       " ('more', 'RBR'),\n",
       " ('colorful', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('unpredictable', 'JJ'),\n",
       " ('micro-level', 'JJ'),\n",
       " ('interactions—one', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('topics,', 'NN'),\n",
       " ('Does', 'NNP'),\n",
       " ('science', 'VB'),\n",
       " ('make', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('better,', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('initiated', 'VBN'),\n",
       " ('from', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('casual', 'JJ'),\n",
       " ('conversation', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('volunteer', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('few', 'JJ'),\n",
       " ('participants.', 'NN'),\n",
       " ('Feeling', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('power', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('ensemble', 'JJ'),\n",
       " ('theory', 'NN'),\n",
       " ('through', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('real-life', 'JJ'),\n",
       " ('exercise,', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " ('embrace', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('core', 'NN'),\n",
       " ('idea.', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('cannot', 'VBP'),\n",
       " ('account', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('interaction', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('millisecond.', 'NN'),\n",
       " ('Regardless,', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('now', 'RB'),\n",
       " ('believe', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('find', 'VB'),\n",
       " ('ways', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('grasp', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('complexity', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('world', 'NN'),\n",
       " ('while', 'IN'),\n",
       " ('embracing', 'VBG'),\n",
       " ('our', 'PRP$'),\n",
       " ('limitations', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('humbly', 'RB'),\n",
       " ('accepting', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('uncontrollable', 'JJ'),\n",
       " ('versatility.', 'NN'),\n",
       " ('From', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('scientist’s', 'NN'),\n",
       " ('viewpoint,', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('sound', 'VB'),\n",
       " ('ironic.', 'JJ'),\n",
       " ('Still,', 'NNP'),\n",
       " ('ensemble', 'JJ'),\n",
       " ('theory', 'NN'),\n",
       " ('taught', 'VBD'),\n",
       " ('me', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('gaze', 'VB'),\n",
       " ('upon', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('bigger', 'JJR'),\n",
       " ('picture,', 'NN'),\n",
       " ('observe', 'VB'),\n",
       " ('how', 'WRB'),\n",
       " ('the', 'DT'),\n",
       " ('frames', 'NNS'),\n",
       " ('connect', 'VBP'),\n",
       " ('and', 'CC'),\n",
       " ('see', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('true', 'JJ'),\n",
       " ('meaning', 'NN'),\n",
       " ('embedded', 'VBD'),\n",
       " ('behind', 'IN'),\n",
       " ('all', 'PDT'),\n",
       " ('the', 'DT'),\n",
       " ('complexity.', 'NN'),\n",
       " ('During', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('Statistical', 'JJ'),\n",
       " ('Physics', 'NNP'),\n",
       " ('(PH312)', 'NNP'),\n",
       " ('class', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('KAIST,', 'NNP'),\n",
       " ('the', 'DT'),\n",
       " ('professor', 'NN'),\n",
       " ('asked', 'VBD'),\n",
       " ('me', 'PRP'),\n",
       " ('what', 'WP'),\n",
       " ('I', 'PRP'),\n",
       " ('knew', 'VBD'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('concept', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('ensemble.', 'NN'),\n",
       " ('After', 'IN'),\n",
       " ('sharing', 'VBG'),\n",
       " ('my', 'PRP$'),\n",
       " ('experiences,', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('warmly', 'VBZ'),\n",
       " ('smiled', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('said:', 'JJ'),\n",
       " ('\"Good', 'NN'),\n",
       " ('start.\"', 'NN')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/kimkwangil/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m                             \u001b[0menv_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m                         )\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[0;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[1;32m    696\u001b[0m         find_binary_iter(\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         )\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[0;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[1;32m    680\u001b[0m     for file in find_file_iter(\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mpath_to_bin\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m     ):\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m                                         \"https://docs.brew.sh/Installation then `brew install ghostscript`\")                \n\u001b[1;32m    818\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('Statistical', 'JJ'), ('Physics', 'NNPS'), ('is', 'VBZ'), ('a', 'DT'), ('comedy', 'NN'), ('in', 'IN'), ('long-shot.', 'NN'), ('Professor', 'NNP'), ('Nir', 'NNP'), ('Gov’s', 'NNP'), ('lecture', 'NN'), ('(held', 'NN'), ('during', 'IN'), ('the', 'DT'), ('summer', 'NN'), ('camp', 'NN'), ('at', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('Weizmann', 'NNP'), ('Institute', 'NNP')]), ('of', 'IN'), ('Science,', 'NNP'), ('Israel)', 'NNP'), ('covered', 'VBD'), ('a', 'DT'), ('single', 'JJ'), ('topic', 'NN'), ('in', 'IN'), ('physics.', 'JJ'), ('However,', 'NNP'), ('its', 'PRP$'), ('application', 'NN'), ('was', 'VBD'), ('truly', 'RB'), ('versatile—from', 'JJ'), ('cell', 'NN'), ('dynamics', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('collaboration', 'NN'), ('patterns', 'NNS'), ('of', 'IN'), ('ants.', 'JJ'), ('Full', 'NNP'), ('of', 'IN'), ('curiosity,', 'NN'), ('I', 'PRP'), ('approached', 'VBD'), ('him', 'PRP'), ('after', 'IN'), ('the', 'DT'), ('lecture', 'NN'), ('and', 'CC'), ('asked', 'VBD'), ('to', 'TO'), ('learn', 'VB'), ('more', 'JJR'), ('about', 'IN'), ('the', 'DT'), ('magical', 'JJ'), ('tool', 'NN'), ('known', 'VBN'), ('as', 'IN'), Tree('ORGANIZATION', [('Statistical', 'JJ')]), ('Physics.', 'NNP'), ('“Start', 'NN'), ('with', 'IN'), ('ensemble', 'JJ'), ('theory,”', 'NN'), ('he', 'PRP'), ('advised.', 'VBZ'), ('Though,', 'NNP'), ('Statistical', 'NNP'), Tree('PERSON', [('Physics', 'NNP')]), ('seemed', 'VBD'), ('more', 'JJR'), ('of', 'IN'), ('a', 'DT'), ('tragedy,', 'NN'), ('seen', 'VBN'), ('in', 'IN'), ('close-up.', 'JJ'), ('Spending', 'NN'), ('weeks', 'NNS'), ('with', 'IN'), ('several', 'JJ'), ('textbooks,', 'NNS'), ('I', 'PRP'), ('found', 'VBD'), ('myself', 'PRP'), ('in', 'IN'), ('a', 'DT'), ('maze.', 'NN'), ('To', 'TO'), ('understand', 'VB'), ('a', 'DT'), ('system,', 'NN'), ('you', 'PRP'), ('shall', 'MD'), ('calculate', 'VB'), ('every', 'DT'), ('component’s', 'NN'), ('behavior.', 'NN'), ('This', 'DT'), ('commandment', 'NN'), ('summarizes', 'VBZ'), ('the', 'DT'), ('physics', 'NNS'), ('I', 'PRP'), ('had', 'VBD'), ('learned', 'VBN'), ('for', 'IN'), ('three', 'CD'), ('years', 'NNS'), ('at', 'IN'), Tree('ORGANIZATION', [('Korea', 'NNP'), ('Science', 'NNP'), ('Academy', 'NNP')]), ('(KSA).', 'NNP'), ('However,', 'NNP'), ('when', 'WRB'), ('we', 'PRP'), ('consider', 'VBP'), ('a', 'DT'), ('system', 'NN'), ('with', 'IN'), ('a', 'DT'), ('myriad', 'NN'), ('of', 'IN'), ('particles,', 'NN'), ('this', 'DT'), ('directive', 'NN'), ('is', 'VBZ'), ('defied', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('virtual', 'JJ'), ('impossibility', 'NN'), ('of', 'IN'), ('figuring', 'VBG'), ('out', 'RP'), ('the', 'DT'), ('motions', 'NNS'), ('of', 'IN'), ('every', 'DT'), ('particle.', 'NN'), ('Instead,', 'NNP'), ('physicists', 'VBZ'), ('construct', 'VBP'), ('the', 'DT'), ('ensemble', 'NN'), ('of', 'IN'), ('macroscopic', 'NN'), ('snapshots', 'NNS'), ('for', 'IN'), ('a', 'DT'), ('system.', 'NN'), ('The', 'DT'), ('snapshots', 'NNS'), ('contain', 'VBP'), ('different', 'JJ'), ('particle', 'NN'), ('arrangements', 'NNS'), ('and', 'CC'), ('movements', 'NNS'), ('as', 'IN'), ('a', 'DT'), ('“collection.”', 'NN'), ('As', 'RB'), ('far', 'RB'), ('as', 'IN'), ('I', 'PRP'), ('understood,', 'VBP'), ('ensemble', 'JJ'), ('theory', 'NN'), ('was', 'VBD'), ('similar', 'JJ'), ('to', 'TO'), ('understanding', 'VBG'), ('the', 'DT'), ('theme', 'NN'), ('of', 'IN'), ('a', 'DT'), ('movie', 'NN'), ('by', 'IN'), ('watching', 'VBG'), ('a', 'DT'), ('preview', 'NN'), ('that', 'IN'), ('only', 'RB'), ('consists', 'VBZ'), ('of', 'IN'), ('the', 'DT'), ('important', 'JJ'), ('scenes.', 'NN'), ('Hypothetically,', 'NNP'), ('if', 'IN'), ('I', 'PRP'), ('were', 'VBD'), ('to', 'TO'), ('analyze', 'VB'), ('every', 'DT'), ('actor,', 'NN'), ('every', 'DT'), ('line,', 'NN'), ('and', 'CC'), ('every', 'DT'), ('frame,', 'NN'), ('it', 'PRP'), ('would', 'MD'), ('actually', 'RB'), ('hinder', 'VB'), ('me', 'PRP'), ('from', 'IN'), ('grasping', 'VBG'), ('the', 'DT'), ('overall', 'JJ'), ('message', 'NN'), ('of', 'IN'), ('the', 'DT'), ('film.', 'NN'), ('In', 'IN'), ('short,', 'NN'), ('the', 'DT'), ('theory', 'NN'), ('states', 'VBZ'), ('that', 'IN'), ('a', 'DT'), ('state', 'NN'), ('of', 'IN'), ('matter', 'NN'), ('can', 'MD'), ('be', 'VB'), ('understood', 'VBN'), ('without', 'IN'), ('knowing', 'VBG'), ('the', 'DT'), ('movements', 'NNS'), ('of', 'IN'), ('each', 'DT'), ('and', 'CC'), ('every', 'DT'), ('particle.', 'NN'), ('At', 'IN'), ('odds', 'NNS'), ('with', 'IN'), ('my', 'PRP$'), ('existing', 'VBG'), ('beliefs,', 'NN'), ('this', 'DT'), ('new', 'JJ'), ('approach', 'NN'), ('refused', 'VBD'), ('to', 'TO'), ('settle', 'VB'), ('in', 'IN'), ('my', 'PRP$'), ('brain.', 'NN'), ('Even', 'RB'), ('well-designed', 'JJ'), ('exercise', 'NN'), ('problems', 'NNS'), ('in', 'IN'), ('textbooks', 'NNS'), ('could', 'MD'), ('not', 'RB'), ('save', 'VB'), ('me', 'PRP'), ('from', 'IN'), ('drowning', 'VBG'), ('in', 'IN'), ('confusion.', 'NN'), ('Meanwhile,', 'NNP'), ('ensemble', 'JJ'), ('theory', 'NN'), ('suggested', 'VBD'), ('a', 'DT'), ('possible', 'JJ'), ('explanation', 'NN'), ('for', 'IN'), ('unanswered', 'JJ'), ('questions', 'NNS'), ('from', 'IN'), ('my', 'PRP$'), ('leadership', 'NN'), ('during', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('KSA', 'NNP'), ('Science', 'NNP')]), ('Fair.', 'NNP'), ('To', 'TO'), ('successfully', 'RB'), ('manage', 'VB'), ('KSA’s', 'NNP'), ('largest', 'JJS'), ('international', 'JJ'), ('festival,', 'NN'), ('I', 'PRP'), ('provided', 'VBD'), ('detailed', 'JJ'), ('instructions', 'NNS'), ('to', 'TO'), ('each', 'DT'), ('volunteer.', 'NN'), ('For', 'IN'), ('example,', 'NN'), ('I', 'PRP'), ('assigned', 'VBD'), ('each', 'DT'), ('of', 'IN'), ('the', 'DT'), ('fifteen', 'JJ'), ('volunteers', 'NNS'), ('a', 'DT'), ('specific', 'JJ'), ('task,', 'NN'), ('like', 'IN'), ('the', 'DT'), ('placement', 'NN'), ('of', 'IN'), ('posters', 'NNS'), ('and', 'CC'), ('strict', 'JJ'), ('discussion', 'NN'), ('guidelines', 'NNS'), ('in', 'IN'), ('sessions,', 'NN'), ('before', 'IN'), ('the', 'DT'), ('start', 'NN'), ('of', 'IN'), ('every', 'DT'), ('presentation.', 'NN'), ('Despite', 'IN'), ('my', 'PRP$'), ('efforts', 'NNS'), ('in', 'IN'), ('trying', 'VBG'), ('to', 'TO'), ('control', 'VB'), ('all', 'DT'), ('aspects,', 'VB'), ('some', 'DT'), ('problems', 'NNS'), ('emerged', 'VBD'), ('as', 'IN'), ('some', 'DT'), ('volunteers', 'NNS'), ('starting', 'VBG'), ('to', 'TO'), ('miss', 'VB'), ('the', 'DT'), ('detailed', 'JJ'), ('plan', 'NN'), ('of', 'IN'), ('action.', 'JJ'), ('Initially,', 'NNP'), ('I', 'PRP'), ('was', 'VBD'), ('clueless', 'NN'), ('as', 'IN'), ('I', 'PRP'), ('tried', 'VBD'), ('to', 'TO'), ('understand', 'VB'), ('how', 'WRB'), ('such', 'JJ'), ('a', 'DT'), ('detailed', 'JJ'), ('plan', 'NN'), ('and', 'CC'), ('execution', 'NN'), ('could', 'MD'), ('go', 'VB'), ('haywire;', 'RB'), ('however,', 'RB'), ('as', 'IN'), ('my', 'PRP$'), ('knowledge', 'NN'), ('in', 'IN'), ('ensemble', 'JJ'), ('theory', 'NN'), ('deepened,', 'NN'), ('I', 'PRP'), ('began', 'VBD'), ('to', 'TO'), ('realize', 'VB'), ('the', 'DT'), ('fundamental', 'JJ'), ('problems', 'NNS'), ('rooted', 'VBN'), ('in', 'IN'), ('my', 'PRP$'), ('approach.', 'JJ'), ('Instead', 'RB'), ('of', 'IN'), ('micromanagement,', 'NN'), ('I', 'PRP'), ('should', 'MD'), ('have', 'VB'), ('viewed', 'VBN'), Tree('ORGANIZATION', [('KSASF', 'NNP')]), ('as', 'IN'), ('an', 'DT'), ('ensemble', 'NN'), ('and', 'CC'), ('seen', 'VBN'), ('the', 'DT'), ('bigger', 'JJR'), ('picture', 'NN'), ('of', 'IN'), ('KSASF.', 'NNP'), ('As', 'IN'), ('the', 'DT'), ('head', 'NN'), ('volunteer,', 'NN'), ('I', 'PRP'), ('should', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('brave', 'VBN'), ('enough', 'JJ'), ('to', 'TO'), ('take', 'VB'), ('a', 'DT'), ('step', 'NN'), ('back,', 'NN'), ('observe,', 'NN'), ('and', 'CC'), ('created', 'VBD'), ('a', 'DT'), ('macroscopic', 'NN'), ('background', 'NN'), ('that', 'WDT'), ('honors', 'VBZ'), ('the', 'DT'), ('core', 'NN'), ('essence', 'NN'), ('of', 'IN'), ('KSASF—the', 'NNP'), ('exchange', 'NN'), ('of', 'IN'), ('scientific', 'JJ'), ('ideas.', 'NN'), ('Given', 'NNP'), ('a', 'DT'), ('second', 'JJ'), ('chance', 'NN'), ('to', 'TO'), ('be', 'VB'), ('the', 'DT'), ('head', 'JJ'), ('volunteer', 'NN'), ('of', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('KSA', 'NNP'), ('Youth', 'NNP'), ('Science', 'NNP')]), ('Camp,', 'NNP'), ('a', 'DT'), ('mentoring', 'JJ'), ('event', 'NN'), ('for', 'IN'), ('sixty', 'NN'), ('elementary', 'NN'), ('and', 'CC'), ('middle', 'JJ'), ('school', 'NN'), ('students,', 'NN'), ('I', 'PRP'), ('envisioned', 'VBD'), ('the', 'DT'), ('camp’s', 'NN'), ('activities', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('perspective', 'NN'), ('of', 'IN'), ('an', 'DT'), ('ensemble,', 'NN'), ('where', 'WRB'), ('each', 'DT'), ('event', 'NN'), ('of', 'IN'), ('the', 'DT'), ('camp', 'NN'), ('should', 'MD'), ('align', 'VB'), ('with', 'IN'), ('the', 'DT'), ('camp’s', 'NN'), ('core', 'NN'), ('message—learning', 'VBG'), ('science', 'NN'), ('from', 'IN'), ('inquiries.', 'NN'), ('I', 'PRP'), ('designed', 'VBD'), ('the', 'DT'), ('events', 'NNS'), ('with', 'IN'), ('macroscopic', 'NN'), ('thinking:', 'NN'), ('being', 'VBG'), ('relevant', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('given', 'VBN'), ('theme', 'NN'), ('but', 'CC'), ('minimizing', 'VBG'), ('its', 'PRP$'), ('structure', 'NN'), ('and', 'CC'), ('guidelines.', 'NN'), ('This', 'DT'), ('encouraged', 'VBD'), ('the', 'DT'), ('volunteers', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('more', 'JJR'), ('proactive,', 'JJ'), ('fully', 'RB'), ('showing', 'VBG'), ('their', 'PRP$'), ('expertise', 'NN'), ('in', 'IN'), ('dynamic', 'JJ'), ('‘open', 'JJ'), ('discussion', 'NN'), ('sessions.’', 'NN'), ('Compared', 'NNP'), ('to', 'TO'), ('KSASF,', 'VB'), ('the', 'DT'), ('camp', 'NN'), ('became', 'VBD'), ('more', 'RBR'), ('colorful', 'JJ'), ('with', 'IN'), ('unpredictable', 'JJ'), ('micro-level', 'JJ'), ('interactions—one', 'NN'), ('of', 'IN'), ('the', 'DT'), ('topics,', 'NN'), ('Does', 'NNP'), ('science', 'VB'), ('make', 'VB'), ('the', 'DT'), ('world', 'NN'), ('better,', 'NN'), ('was', 'VBD'), ('initiated', 'VBN'), ('from', 'IN'), ('a', 'DT'), ('casual', 'JJ'), ('conversation', 'NN'), ('between', 'IN'), ('a', 'DT'), ('volunteer', 'NN'), ('and', 'CC'), ('few', 'JJ'), ('participants.', 'NN'), ('Feeling', 'VBG'), ('the', 'DT'), ('power', 'NN'), ('of', 'IN'), ('ensemble', 'JJ'), ('theory', 'NN'), ('through', 'IN'), ('a', 'DT'), ('real-life', 'JJ'), ('exercise,', 'NN'), ('I', 'PRP'), ('could', 'MD'), ('embrace', 'VB'), ('its', 'PRP$'), ('core', 'NN'), ('idea.', 'NN'), ('I', 'PRP'), ('cannot', 'VBP'), ('account', 'NN'), ('for', 'IN'), ('every', 'DT'), ('interaction', 'NN'), ('in', 'IN'), ('every', 'DT'), ('millisecond.', 'NN'), ('Regardless,', 'NNP'), ('I', 'PRP'), ('now', 'RB'), ('believe', 'VBP'), ('that', 'IN'), ('we', 'PRP'), ('may', 'MD'), ('find', 'VB'), ('ways', 'NNS'), ('to', 'TO'), ('grasp', 'VB'), ('the', 'DT'), ('complexity', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('world', 'NN'), ('while', 'IN'), ('embracing', 'VBG'), ('our', 'PRP$'), ('limitations', 'NNS'), ('and', 'CC'), ('humbly', 'RB'), ('accepting', 'VBG'), ('the', 'DT'), ('uncontrollable', 'JJ'), ('versatility.', 'NN'), ('From', 'IN'), ('a', 'DT'), ('scientist’s', 'NN'), ('viewpoint,', 'IN'), ('it', 'PRP'), ('may', 'MD'), ('sound', 'VB'), ('ironic.', 'JJ'), ('Still,', 'NNP'), ('ensemble', 'JJ'), ('theory', 'NN'), ('taught', 'VBD'), ('me', 'PRP'), ('to', 'TO'), ('gaze', 'VB'), ('upon', 'IN'), ('the', 'DT'), ('bigger', 'JJR'), ('picture,', 'NN'), ('observe', 'VB'), ('how', 'WRB'), ('the', 'DT'), ('frames', 'NNS'), ('connect', 'VBP'), ('and', 'CC'), ('see', 'VBP'), ('the', 'DT'), ('true', 'JJ'), ('meaning', 'NN'), ('embedded', 'VBD'), ('behind', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('complexity.', 'NN'), ('During', 'IN'), ('a', 'DT'), ('Statistical', 'JJ'), Tree('PERSON', [('Physics', 'NNP')]), ('(PH312)', 'NNP'), ('class', 'NN'), ('at', 'IN'), ('KAIST,', 'NNP'), ('the', 'DT'), ('professor', 'NN'), ('asked', 'VBD'), ('me', 'PRP'), ('what', 'WP'), ('I', 'PRP'), ('knew', 'VBD'), ('about', 'IN'), ('the', 'DT'), ('concept', 'NN'), ('of', 'IN'), ('ensemble.', 'NN'), ('After', 'IN'), ('sharing', 'VBG'), ('my', 'PRP$'), ('experiences,', 'NN'), ('he', 'PRP'), ('warmly', 'VBZ'), ('smiled', 'VBN'), ('and', 'CC'), ('said:', 'JJ'), ('\"Good', 'NN'), ('start.\"', 'NN')])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.ne_chunk(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-8ebdac77d187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0mdraw_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[0;34m(*trees)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \"\"\"\n\u001b[0;32m-> 1008\u001b[0;31m     \u001b[0mTreeView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nltk.ne_chunk(tags).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7a281dac6f6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMecab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmecab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMecab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "def text_cleaning():\n",
    "    doc = re.sub(\"[^ㄱ-ㅎ ㅏ-ㅣ가-힇 ]\", \"\", doc)\n",
    "    return doc\n",
    "\n",
    "def define_stopwords(path):\n",
    "    SW = set()\n",
    "    SW.add(\"있다\")\n",
    "    #stopword-ko.txt에 직접 추가하기 - 파일에 직접 넣는다.\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for word in f:\n",
    "            SW.add(word)\n",
    "def text_tokenizing(doc):\n",
    "    \n",
    "    return [word for word in mecab.morphs(doc) if word not in SW and len(word) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"렁ㄴㅁ러댜ㅐㅈ러리렁니멀애ㅓ이널나는 종료된 것을 이렇게 제안하연 어쩌구 어쩌구 저쩌구 해서 처리한다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5f7c2e48dc15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stopwords-ko.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_tokenizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'define_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "SW = define_stopwords(\"stopwords-ko.txt\")\n",
    "\n",
    "cleaned_text = text_cleaning(text3)\n",
    "\n",
    "tokenized_text = text_tokenizing(cleaned_text)\n",
    "print(\"\\n형태소 분석 : \", tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 181kB/s eta 0:00:01    |█████████▍                      | 5.7MB 91kB/s eta 0:02:30     |██████████████▊                 | 8.9MB 167kB/s eta 0:01:03\n",
      "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/7a/52a266ca5566b0aea704fa8fc986d92eeaaa47ffcf61598b86a1e007bf9e/JPype1-0.7.2.tar.gz (537kB)\n",
      "\u001b[K     |████████████████████████████████| 542kB 337kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting beautifulsoup4==4.6.0 (from konlpy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 290kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: colorama in /anaconda3/lib/python3.6/site-packages (from konlpy) (0.4.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /anaconda3/lib/python3.6/site-packages (from konlpy) (4.2.5)\n",
      "Collecting tweepy>=3.7.0 (from konlpy)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.6 in /anaconda3/lib/python3.6/site-packages (from konlpy) (1.16.4)\n",
      "Collecting requests-oauthlib>=0.7.0 (from tweepy>=3.7.0->konlpy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /anaconda3/lib/python3.6/site-packages (from tweepy>=3.7.0->konlpy) (1.6.8)\n",
      "Requirement already satisfied: requests>=2.11.1 in /anaconda3/lib/python3.6/site-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/kimkwangil/.local/lib/python3.6/site-packages (from tweepy>=3.7.0->konlpy) (1.14.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 373kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Building wheels for collected packages: JPype1\n",
      "  Building wheel for JPype1 (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Complete output from command /anaconda3/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/private/var/folders/c5/9vy8j2pj70194d1_1vqy4c880000gn/T/pip-install-__vukjje/JPype1/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/c5/9vy8j2pj70194d1_1vqy4c880000gn/T/pip-wheel-169z2d5q --python-tag cp36:\u001b[0m\n",
      "\u001b[31m  ERROR: /anaconda3/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jcollection.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jcomparable.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_classpath.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jio.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jtypes.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_pykeywords.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jproxy.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_gui.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_darwin.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jmethod.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/nio.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jstring.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_cygwin.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/types.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/beans.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jvmfinder.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/imports.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jcustomizer.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_core.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jinit.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_linux.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jarray.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jobject.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/pickle.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jclass.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_windows.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jexception.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/reflect.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  copying jpype/_jpackage.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "  running build_ext\n",
      "  running build_java\n",
      "  Using Jar cache\n",
      "  creating build/lib\n",
      "  creating build/lib/org\n",
      "  creating build/lib/org/jpype\n",
      "  creating build/lib/org/jpype/classloader\n",
      "  copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "  copying native/jars/org.jpype.jar -> build/lib\n",
      "  running build_thunk\n",
      "  Building thunks\n",
      "    including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "    including thunk build/lib/org.jpype.jar\n",
      "  building '_jpype' extension\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/build\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/build/src\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/native\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/native/python\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/native/common\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -DMACOSX=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/anaconda3/include/python3.6m -c build/src/jp_thunk.cpp -o build/temp.macosx-10.7-x86_64-3.6/build/src/jp_thunk.o -ggdb\n",
      "  warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "  In file included from build/src/jp_thunk.cpp:1:\n",
      "  In file included from build/src/jp_thunk.h:3:\n",
      "  native/common/include/jpype.h:64:10: fatal error: 'map' file not found\n",
      "  #include <map>\n",
      "           ^~~~~\n",
      "  1 warning and 1 error generated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for JPype1\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for JPype1\n",
      "Failed to build JPype1\n",
      "Installing collected packages: JPype1, beautifulsoup4, oauthlib, requests-oauthlib, tweepy, konlpy\n",
      "  Running setup.py install for JPype1 ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Complete output from command /anaconda3/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/private/var/folders/c5/9vy8j2pj70194d1_1vqy4c880000gn/T/pip-install-__vukjje/JPype1/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/c5/9vy8j2pj70194d1_1vqy4c880000gn/T/pip-record-no8lysnc/install-record.txt --single-version-externally-managed --compile:\u001b[0m\n",
      "\u001b[31m    ERROR: /anaconda3/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jcollection.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jcomparable.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_classpath.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jio.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jtypes.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_pykeywords.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jproxy.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_gui.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_darwin.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jmethod.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/nio.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jstring.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_cygwin.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/types.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/beans.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jvmfinder.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/imports.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jcustomizer.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_core.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jinit.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_linux.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jarray.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jobject.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/pickle.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jclass.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_windows.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jexception.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/reflect.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    copying jpype/_jpackage.py -> build/lib.macosx-10.7-x86_64-3.6/jpype\n",
      "    running build_ext\n",
      "    running build_java\n",
      "    Using Jar cache\n",
      "    copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "    copying native/jars/org.jpype.jar -> build/lib\n",
      "    running build_thunk\n",
      "    Building thunks\n",
      "      including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "      including thunk build/lib/org.jpype.jar\n",
      "    building '_jpype' extension\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/build\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/build/src\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/native\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/native/python\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/native/common\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -DMACOSX=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/anaconda3/include/python3.6m -c build/src/jp_thunk.cpp -o build/temp.macosx-10.7-x86_64-3.6/build/src/jp_thunk.o -ggdb\n",
      "    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "    In file included from build/src/jp_thunk.cpp:1:\n",
      "    In file included from build/src/jp_thunk.h:3:\n",
      "    native/common/include/jpype.h:64:10: fatal error: 'map' file not found\n",
      "    #include <map>\n",
      "             ^~~~~\n",
      "    1 warning and 1 error generated.\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Command \"/anaconda3/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/private/var/folders/c5/9vy8j2pj70194d1_1vqy4c880000gn/T/pip-install-__vukjje/JPype1/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/c5/9vy8j2pj70194d1_1vqy4c880000gn/T/pip-record-no8lysnc/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/c5/9vy8j2pj70194d1_1vqy4c880000gn/T/pip-install-__vukjje/JPype1/\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "UniversityMajor/01_Harvard/HarvardPS45P2-04.docx\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd2 in position 16: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e38de45bddd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd2 in position 16: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "#directory = \"UniversityMajor/01_Harvard/\"\n",
    "outfile_name = \"merged_essay.txt\"\n",
    "\n",
    "out_file = open(outfile_name, 'w')\n",
    "#files = os.listdir(directory)\n",
    "files = glob.glob(\"UniversityMajor/01_Harvard/*.docx\") #파일 리스트를 불러온다.\n",
    "for filename in files:\n",
    "    if \".docx\" not in filename:\n",
    "        continue\n",
    "    print(type(filename))\n",
    "    print(filename)\n",
    "    file = open(filename, encoding='utf-8')\n",
    "    for line in file:\n",
    "        out_file.write(line)\n",
    "    out_file.write(line)\n",
    "    out_file.write(\"\\n\")\n",
    "    file.close()\n",
    "out_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proprocessing:  ['Statistical Physics is a comedy in long-shot. Professor Nir Gov’s lecture (held during the summer camp at the Weizmann Institute of Science, Israel) covered a single topic in physics. However, its application was truly versatile—from cell dynamics to the collaboration patterns of ants. Full of curiosity, I approached him after the lecture and asked to learn more about the magical tool known as Statistical Physics. ', '', '“Start with ensemble theory,” he advised. ', '', 'Though, Statistical Physics seemed more of a tragedy, seen in close-up. Spending weeks with several textbooks, I found myself in a maze. ', '', 'To understand a system, you shall calculate every component’s behavior. This commandment summarizes the physics I had learned for three years at Korea Science Academy (KSA). However, when we consider a system with a myriad of particles, this directive is defied by the virtual impossibility of figuring out the motions of every particle. Instead, physicists construct the ensemble of macroscopic snapshots for a system. The snapshots contain different particle arrangements and movements as a “collection.”', '', 'As far as I understood, ensemble theory was similar to understanding the theme of a movie by watching a preview that only consists of the important scenes. Hypothetically, if I were to analyze every actor, every line, and every frame, it would actually hinder me from grasping the overall message of the film. In short, the theory states that a state of matter can be understood without knowing the movements of each and every particle. At odds with my existing beliefs, this new approach refused to settle in my brain. Even well-designed exercise problems in textbooks could not save me from drowning in confusion. ', '', 'Meanwhile, ensemble theory suggested a possible explanation for unanswered questions from my leadership during the KSA Science Fair. To successfully manage KSA’s largest international festival, I provided detailed instructions to each volunteer. For example, I assigned each of the fifteen volunteers a specific task, like the placement of posters and strict discussion guidelines in sessions, before the start of every presentation. Despite my efforts in trying to control all aspects, some problems emerged as some volunteers starting to miss the detailed plan of action. Initially, I was clueless as I tried to understand how such a detailed plan and execution could go haywire; however, as my knowledge in ensemble theory deepened, I began to realize the fundamental problems rooted in my approach. ', '', 'Instead of micromanagement, I should have viewed KSASF as an ensemble and seen the bigger picture of KSASF. As the head volunteer, I should have been brave enough to take a step back, observe, and created a macroscopic background that honors the core essence of KSASF—the exchange of scientific ideas. ', '', 'Given a second chance to be the head volunteer of the KSA Youth Science Camp, a mentoring event for sixty elementary and middle school students, I envisioned the camp’s activities in the perspective of an ensemble, where each event of the camp should align with the camp’s core message—learning science from inquiries. I designed the events with macroscopic thinking: being relevant to the given theme but minimizing its structure and guidelines. This encouraged the volunteers to be more proactive, fully showing their expertise in dynamic ‘open discussion sessions.’ Compared to KSASF, the camp became more colorful with unpredictable micro-level interactions—one of the topics, Does science make the world better, was initiated from a casual conversation between a volunteer and few participants. ', '', 'Feeling the power of ensemble theory through a real-life exercise, I could embrace its core idea. I cannot account for every interaction in every millisecond. Regardless, I now believe that we may find ways to grasp the complexity of our world while embracing our limitations and humbly accepting the uncontrollable versatility. From a scientist’s viewpoint, it may sound ironic. Still, ensemble theory taught me to gaze upon the bigger picture, observe how the frames connect and see the true meaning embedded behind all the complexity. ', '', 'During a Statistical Physics (PH) class at KAIST, the professor asked me what I knew about the concept of ensemble. After sharing my experiences, he warmly smiled and said: \"Good start.\"']\n",
      "len of tokens: 840\n",
      "len of set : 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', \"'Statistical\", 'Physics', 'comedy', 'long-shot', '.', 'Professor', 'Nir', 'Gov', '’', 'lecture', '(', 'held', 'summer', 'camp', 'Weizmann', 'Institute', 'Science', ',', 'Israel', ')', 'covered', 'single', 'topic', 'physics', '.', 'However', ',', 'application', 'truly', 'versatile—from', 'cell', 'dynamics', 'collaboration', 'patterns', 'ants', '.', 'Full', 'curiosity', ',', 'I', 'approached', 'lecture', 'asked', 'learn', 'magical', 'tool', 'known', 'Statistical', 'Physics', '.', \"'\", ',', '``', ',', \"'\", '“', 'Start', 'ensemble', 'theory', ',', '”', 'advised', '.', \"'\", ',', '``', ',', \"'Though\", ',', 'Statistical', 'Physics', 'seemed', 'tragedy', ',', 'seen', 'close-up', '.', 'Spending', 'weeks', 'several', 'textbooks', ',', 'I', 'found', 'maze', '.', \"'\", ',', '``', ',', \"'To\", 'understand', 'system', ',', 'shall', 'calculate', 'every', 'component', '’', 'behavior', '.', 'This', 'commandment', 'summarizes', 'physics', 'I', 'learned', 'three', 'years', 'Korea', 'Science', 'Academy', '(', 'KSA', ')', '.', 'However', ',', 'consider', 'system', 'myriad', 'particles', ',', 'directive', 'defied', 'virtual', 'impossibility', 'figuring', 'motions', 'every', 'particle', '.', 'Instead', ',', 'physicists', 'construct', 'ensemble', 'macroscopic', 'snapshots', 'system', '.', 'The', 'snapshots', 'contain', 'different', 'particle', 'arrangements', 'movements', '“', 'collection.', '”', \"'\", ',', '``', ',', \"'As\", 'far', 'I', 'understood', ',', 'ensemble', 'theory', 'similar', 'understanding', 'theme', 'movie', 'watching', 'preview', 'consists', 'important', 'scenes', '.', 'Hypothetically', ',', 'I', 'analyze', 'every', 'actor', ',', 'every', 'line', ',', 'every', 'frame', ',', 'would', 'actually', 'hinder', 'grasping', 'overall', 'message', 'film', '.', 'In', 'short', ',', 'theory', 'states', 'state', 'matter', 'understood', 'without', 'knowing', 'movements', 'every', 'particle', '.', 'At', 'odds', 'existing', 'beliefs', ',', 'new', 'approach', 'refused', 'settle', 'brain', '.', 'Even', 'well-designed', 'exercise', 'problems', 'textbooks', 'could', 'save', 'drowning', 'confusion', '.', \"'\", ',', '``', ',', \"'Meanwhile\", ',', 'ensemble', 'theory', 'suggested', 'possible', 'explanation', 'unanswered', 'questions', 'leadership', 'KSA', 'Science', 'Fair', '.', 'To', 'successfully', 'manage', 'KSA', '’', 'largest', 'international', 'festival', ',', 'I', 'provided', 'detailed', 'instructions', 'volunteer', '.', 'For', 'example', ',', 'I', 'assigned', 'fifteen', 'volunteers', 'specific', 'task', ',', 'like', 'placement', 'posters', 'strict', 'discussion', 'guidelines', 'sessions', ',', 'start', 'every', 'presentation', '.', 'Despite', 'efforts', 'trying', 'control', 'aspects', ',', 'problems', 'emerged', 'volunteers', 'starting', 'miss', 'detailed', 'plan', 'action', '.', 'Initially', ',', 'I', 'clueless', 'I', 'tried', 'understand', 'detailed', 'plan', 'execution', 'could', 'go', 'haywire', ';', 'however', ',', 'knowledge', 'ensemble', 'theory', 'deepened', ',', 'I', 'began', 'realize', 'fundamental', 'problems', 'rooted', 'approach', '.', \"'\", ',', '``', ',', \"'Instead\", 'micromanagement', ',', 'I', 'viewed', 'KSASF', 'ensemble', 'seen', 'bigger', 'picture', 'KSASF', '.', 'As', 'head', 'volunteer', ',', 'I', 'brave', 'enough', 'take', 'step', 'back', ',', 'observe', ',', 'created', 'macroscopic', 'background', 'honors', 'core', 'essence', 'KSASF—the', 'exchange', 'scientific', 'ideas', '.', \"'\", ',', '``', ',', \"'Given\", 'second', 'chance', 'head', 'volunteer', 'KSA', 'Youth', 'Science', 'Camp', ',', 'mentoring', 'event', 'sixty', 'elementary', 'middle', 'school', 'students', ',', 'I', 'envisioned', 'camp', '’', 'activities', 'perspective', 'ensemble', ',', 'event', 'camp', 'align', 'camp', '’', 'core', 'message—learning', 'science', 'inquiries', '.', 'I', 'designed', 'events', 'macroscopic', 'thinking', ':', 'relevant', 'given', 'theme', 'minimizing', 'structure', 'guidelines', '.', 'This', 'encouraged', 'volunteers', 'proactive', ',', 'fully', 'showing', 'expertise', 'dynamic', '‘', 'open', 'discussion', 'sessions.', '’', 'Compared', 'KSASF', ',', 'camp', 'became', 'colorful', 'unpredictable', 'micro-level', 'interactions—one', 'topics', ',', 'Does', 'science', 'make', 'world', 'better', ',', 'initiated', 'casual', 'conversation', 'volunteer', 'participants', '.', \"'\", ',', '``', ',', \"'Feeling\", 'power', 'ensemble', 'theory', 'real-life', 'exercise', ',', 'I', 'could', 'embrace', 'core', 'idea', '.', 'I', 'account', 'every', 'interaction', 'every', 'millisecond', '.', 'Regardless', ',', 'I', 'believe', 'may', 'find', 'ways', 'grasp', 'complexity', 'world', 'embracing', 'limitations', 'humbly', 'accepting', 'uncontrollable', 'versatility', '.', 'From', 'scientist', '’', 'viewpoint', ',', 'may', 'sound', 'ironic', '.', 'Still', ',', 'ensemble', 'theory', 'taught', 'gaze', 'upon', 'bigger', 'picture', ',', 'observe', 'frames', 'connect', 'see', 'true', 'meaning', 'embedded', 'behind', 'complexity', '.', \"'\", ',', '``', ',', \"'During\", 'Statistical', 'Physics', '(', 'PH', ')', 'class', 'KAIST', ',', 'professor', 'asked', 'I', 'knew', 'concept', 'ensemble', '.', 'After', 'sharing', 'experiences', ',', 'warmly', 'smiled', 'said', ':', '``', 'Good', 'start', '.', \"''\", \"'\", ']']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def text_cleaning(doc):\n",
    "    doc = re.sub('[!”#$%&’()*+,,\"\"''-./:;<=>?@[\\]^_`{|}~]:', '', doc)\n",
    "    doc2 = re.sub(r'\\d+', '', doc) # remove numbers\n",
    "    doc3 = doc2.translate(str.maketrans(\"\", \"\"))\n",
    "    doc3.splitlines()\n",
    "    return doc2\n",
    "\n",
    "\n",
    "\n",
    "def text_tokenizing(doc):\n",
    "    return [word for word in mecab.morphs(doc) if word not in SW and len(word) > 1]\n",
    "\n",
    "\n",
    "#txt 파일을 불러온다.\n",
    "text_input=[]\n",
    "\n",
    "file=open(\"HarvardEssays.txt\", 'r')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    \n",
    "    if line:\n",
    "        text_input.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "cleaned_text = text_cleaning(str(text_input))\n",
    "\n",
    "print(\"Proprocessing: \", cleaned_text)\n",
    "\n",
    "\n",
    "from nltk import regexp_tokenize\n",
    "pattern = r'''(?x) ([A-Z]\\.)+ | \\w+(-\\w+)* | \\$?\\d+(\\.\\d+)?%? | \\.\\.\\. | [][.,;\"'?():-_`]'''\n",
    "tokens_en = regexp_tokenize(cleaned_text, pattern)\n",
    "\n",
    "\n",
    "import nltk\n",
    "en = nltk.Text(tokens_en)\n",
    "\n",
    "\n",
    "print(\"len of tokens: {}\".format(len(en.tokens)))    # returns number of tokens (document length)\n",
    "print(\"len of set : {}\".format(len(set(en.tokens))))  # returns number of unique tokens\n",
    "en.vocab()                  # returns frequency distribution\n",
    "\n",
    "\n",
    "en.plot(50)     # Plot sorted frequency of top 50 tokens\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(cleaned_text)\n",
    "result = [i for i in tokens if not i in stop_words]\n",
    "print (result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "'\n",
      "[\n",
      "'\n",
      ",\n",
      "``\n",
      "'statist\n",
      "''\n",
      ",\n",
      "'physic\n",
      "'\n",
      ",\n",
      "'comedi\n",
      "'\n",
      ",\n",
      "'long-shot\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'professor\n",
      "'\n",
      ",\n",
      "'nir\n",
      "'\n",
      ",\n",
      "'gov\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'lectur\n",
      "'\n",
      ",\n",
      "'\n",
      "(\n",
      "'\n",
      ",\n",
      "'held\n",
      "'\n",
      ",\n",
      "'summer\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'weizmann\n",
      "'\n",
      ",\n",
      "'institut\n",
      "'\n",
      ",\n",
      "'scienc\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'israel\n",
      "'\n",
      ",\n",
      "'\n",
      ")\n",
      "'\n",
      ",\n",
      "'cover\n",
      "'\n",
      ",\n",
      "'singl\n",
      "'\n",
      ",\n",
      "'topic\n",
      "'\n",
      ",\n",
      "'physic\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'howev\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'applic\n",
      "'\n",
      ",\n",
      "'truli\n",
      "'\n",
      ",\n",
      "'versatile—from\n",
      "'\n",
      ",\n",
      "'cell\n",
      "'\n",
      ",\n",
      "'dynam\n",
      "'\n",
      ",\n",
      "'collabor\n",
      "'\n",
      ",\n",
      "'pattern\n",
      "'\n",
      ",\n",
      "'ant\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'full\n",
      "'\n",
      ",\n",
      "'curios\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'approach\n",
      "'\n",
      ",\n",
      "'lectur\n",
      "'\n",
      ",\n",
      "'ask\n",
      "'\n",
      ",\n",
      "'learn\n",
      "'\n",
      ",\n",
      "'magic\n",
      "'\n",
      ",\n",
      "'tool\n",
      "'\n",
      ",\n",
      "'known\n",
      "'\n",
      ",\n",
      "'statist\n",
      "'\n",
      ",\n",
      "'physic\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      "“\n",
      "'\n",
      ",\n",
      "'start\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'theori\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "”\n",
      "'\n",
      ",\n",
      "'advis\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'though\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'statist\n",
      "'\n",
      ",\n",
      "'physic\n",
      "'\n",
      ",\n",
      "'seem\n",
      "'\n",
      ",\n",
      "'tragedi\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'seen\n",
      "'\n",
      ",\n",
      "'close-up\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'spend\n",
      "'\n",
      ",\n",
      "'week\n",
      "'\n",
      ",\n",
      "'sever\n",
      "'\n",
      ",\n",
      "'textbook\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'found\n",
      "'\n",
      ",\n",
      "'maze\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'to\n",
      "''\n",
      ",\n",
      "'understand\n",
      "'\n",
      ",\n",
      "'system\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'shall\n",
      "'\n",
      ",\n",
      "'calcul\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'compon\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'behavior\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'thi\n",
      "'\n",
      ",\n",
      "'command\n",
      "'\n",
      ",\n",
      "'summar\n",
      "'\n",
      ",\n",
      "'physic\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'learn\n",
      "'\n",
      ",\n",
      "'three\n",
      "'\n",
      ",\n",
      "'year\n",
      "'\n",
      ",\n",
      "'korea\n",
      "'\n",
      ",\n",
      "'scienc\n",
      "'\n",
      ",\n",
      "'academi\n",
      "'\n",
      ",\n",
      "'\n",
      "(\n",
      "'\n",
      ",\n",
      "'ksa\n",
      "'\n",
      ",\n",
      "'\n",
      ")\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'howev\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'consid\n",
      "'\n",
      ",\n",
      "'system\n",
      "'\n",
      ",\n",
      "'myriad\n",
      "'\n",
      ",\n",
      "'particl\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'direct\n",
      "'\n",
      ",\n",
      "'defi\n",
      "'\n",
      ",\n",
      "'virtual\n",
      "'\n",
      ",\n",
      "'imposs\n",
      "'\n",
      ",\n",
      "'figur\n",
      "'\n",
      ",\n",
      "'motion\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'particl\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'instead\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'physicist\n",
      "'\n",
      ",\n",
      "'construct\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'macroscop\n",
      "'\n",
      ",\n",
      "'snapshot\n",
      "'\n",
      ",\n",
      "'system\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'the\n",
      "'\n",
      ",\n",
      "'snapshot\n",
      "'\n",
      ",\n",
      "'contain\n",
      "'\n",
      ",\n",
      "'differ\n",
      "'\n",
      ",\n",
      "'particl\n",
      "'\n",
      ",\n",
      "'arrang\n",
      "'\n",
      ",\n",
      "'movement\n",
      "'\n",
      ",\n",
      "'\n",
      "“\n",
      "'\n",
      ",\n",
      "'collect\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "”\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'a\n",
      "''\n",
      ",\n",
      "'far\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'understood\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'theori\n",
      "'\n",
      ",\n",
      "'similar\n",
      "'\n",
      ",\n",
      "'understand\n",
      "'\n",
      ",\n",
      "'theme\n",
      "'\n",
      ",\n",
      "'movi\n",
      "'\n",
      ",\n",
      "'watch\n",
      "'\n",
      ",\n",
      "'preview\n",
      "'\n",
      ",\n",
      "'consist\n",
      "'\n",
      ",\n",
      "'import\n",
      "'\n",
      ",\n",
      "'scene\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'hypothet\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'analyz\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'actor\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'line\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'frame\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'would\n",
      "'\n",
      ",\n",
      "'actual\n",
      "'\n",
      ",\n",
      "'hinder\n",
      "'\n",
      ",\n",
      "'grasp\n",
      "'\n",
      ",\n",
      "'overal\n",
      "'\n",
      ",\n",
      "'messag\n",
      "'\n",
      ",\n",
      "'film\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'in\n",
      "'\n",
      ",\n",
      "'short\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'theori\n",
      "'\n",
      ",\n",
      "'state\n",
      "'\n",
      ",\n",
      "'state\n",
      "'\n",
      ",\n",
      "'matter\n",
      "'\n",
      ",\n",
      "'understood\n",
      "'\n",
      ",\n",
      "'without\n",
      "'\n",
      ",\n",
      "'know\n",
      "'\n",
      ",\n",
      "'movement\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'particl\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'at\n",
      "'\n",
      ",\n",
      "'odd\n",
      "'\n",
      ",\n",
      "'exist\n",
      "'\n",
      ",\n",
      "'belief\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'new\n",
      "'\n",
      ",\n",
      "'approach\n",
      "'\n",
      ",\n",
      "'refus\n",
      "'\n",
      ",\n",
      "'settl\n",
      "'\n",
      ",\n",
      "'brain\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'even\n",
      "'\n",
      ",\n",
      "'well-design\n",
      "'\n",
      ",\n",
      "'exercis\n",
      "'\n",
      ",\n",
      "'problem\n",
      "'\n",
      ",\n",
      "'textbook\n",
      "'\n",
      ",\n",
      "'could\n",
      "'\n",
      ",\n",
      "'save\n",
      "'\n",
      ",\n",
      "'drown\n",
      "'\n",
      ",\n",
      "'confus\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'meanwhil\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'theori\n",
      "'\n",
      ",\n",
      "'suggest\n",
      "'\n",
      ",\n",
      "'possibl\n",
      "'\n",
      ",\n",
      "'explan\n",
      "'\n",
      ",\n",
      "'unansw\n",
      "'\n",
      ",\n",
      "'question\n",
      "'\n",
      ",\n",
      "'leadership\n",
      "'\n",
      ",\n",
      "'ksa\n",
      "'\n",
      ",\n",
      "'scienc\n",
      "'\n",
      ",\n",
      "'fair\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'to\n",
      "'\n",
      ",\n",
      "'success\n",
      "'\n",
      ",\n",
      "'manag\n",
      "'\n",
      ",\n",
      "'ksa\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'largest\n",
      "'\n",
      ",\n",
      "'intern\n",
      "'\n",
      ",\n",
      "'festiv\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'provid\n",
      "'\n",
      ",\n",
      "'detail\n",
      "'\n",
      ",\n",
      "'instruct\n",
      "'\n",
      ",\n",
      "'volunt\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'for\n",
      "'\n",
      ",\n",
      "'exampl\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'assign\n",
      "'\n",
      ",\n",
      "'fifteen\n",
      "'\n",
      ",\n",
      "'volunt\n",
      "'\n",
      ",\n",
      "'specif\n",
      "'\n",
      ",\n",
      "'task\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'like\n",
      "'\n",
      ",\n",
      "'placement\n",
      "'\n",
      ",\n",
      "'poster\n",
      "'\n",
      ",\n",
      "'strict\n",
      "'\n",
      ",\n",
      "'discuss\n",
      "'\n",
      ",\n",
      "'guidelin\n",
      "'\n",
      ",\n",
      "'session\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'start\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'present\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'despit\n",
      "'\n",
      ",\n",
      "'effort\n",
      "'\n",
      ",\n",
      "'tri\n",
      "'\n",
      ",\n",
      "'control\n",
      "'\n",
      ",\n",
      "'aspect\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'problem\n",
      "'\n",
      ",\n",
      "'emerg\n",
      "'\n",
      ",\n",
      "'volunt\n",
      "'\n",
      ",\n",
      "'start\n",
      "'\n",
      ",\n",
      "'miss\n",
      "'\n",
      ",\n",
      "'detail\n",
      "'\n",
      ",\n",
      "'plan\n",
      "'\n",
      ",\n",
      "'action\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'initi\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'clueless\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'tri\n",
      "'\n",
      ",\n",
      "'understand\n",
      "'\n",
      ",\n",
      "'detail\n",
      "'\n",
      ",\n",
      "'plan\n",
      "'\n",
      ",\n",
      "'execut\n",
      "'\n",
      ",\n",
      "'could\n",
      "'\n",
      ",\n",
      "'go\n",
      "'\n",
      ",\n",
      "'haywir\n",
      "'\n",
      ",\n",
      "'\n",
      ";\n",
      "'\n",
      ",\n",
      "'howev\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'knowledg\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'theori\n",
      "'\n",
      ",\n",
      "'deepen\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'began\n",
      "'\n",
      ",\n",
      "'realiz\n",
      "'\n",
      ",\n",
      "'fundament\n",
      "'\n",
      ",\n",
      "'problem\n",
      "'\n",
      ",\n",
      "'root\n",
      "'\n",
      ",\n",
      "'approach\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'instead\n",
      "''\n",
      ",\n",
      "'micromanag\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'view\n",
      "'\n",
      ",\n",
      "'ksasf\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'seen\n",
      "'\n",
      ",\n",
      "'bigger\n",
      "'\n",
      ",\n",
      "'pictur\n",
      "'\n",
      ",\n",
      "'ksasf\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'a\n",
      "'\n",
      ",\n",
      "'head\n",
      "'\n",
      ",\n",
      "'volunt\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'brave\n",
      "'\n",
      ",\n",
      "'enough\n",
      "'\n",
      ",\n",
      "'take\n",
      "'\n",
      ",\n",
      "'step\n",
      "'\n",
      ",\n",
      "'back\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'observ\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'creat\n",
      "'\n",
      ",\n",
      "'macroscop\n",
      "'\n",
      ",\n",
      "'background\n",
      "'\n",
      ",\n",
      "'honor\n",
      "'\n",
      ",\n",
      "'core\n",
      "'\n",
      ",\n",
      "'essenc\n",
      "'\n",
      ",\n",
      "'ksasf—th\n",
      "'\n",
      ",\n",
      "'exchang\n",
      "'\n",
      ",\n",
      "'scientif\n",
      "'\n",
      ",\n",
      "'idea\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'given\n",
      "''\n",
      ",\n",
      "'second\n",
      "'\n",
      ",\n",
      "'chanc\n",
      "'\n",
      ",\n",
      "'head\n",
      "'\n",
      ",\n",
      "'volunt\n",
      "'\n",
      ",\n",
      "'ksa\n",
      "'\n",
      ",\n",
      "'youth\n",
      "'\n",
      ",\n",
      "'scienc\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'mentor\n",
      "'\n",
      ",\n",
      "'event\n",
      "'\n",
      ",\n",
      "'sixti\n",
      "'\n",
      ",\n",
      "'elementari\n",
      "'\n",
      ",\n",
      "'middl\n",
      "'\n",
      ",\n",
      "'school\n",
      "'\n",
      ",\n",
      "'student\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'envis\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'activ\n",
      "'\n",
      ",\n",
      "'perspect\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'event\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'align\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'core\n",
      "'\n",
      ",\n",
      "'message—learn\n",
      "'\n",
      ",\n",
      "'scienc\n",
      "'\n",
      ",\n",
      "'inquiri\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'design\n",
      "'\n",
      ",\n",
      "'event\n",
      "'\n",
      ",\n",
      "'macroscop\n",
      "'\n",
      ",\n",
      "'think\n",
      "'\n",
      ",\n",
      "'\n",
      ":\n",
      "'\n",
      ",\n",
      "'relev\n",
      "'\n",
      ",\n",
      "'given\n",
      "'\n",
      ",\n",
      "'theme\n",
      "'\n",
      ",\n",
      "'minim\n",
      "'\n",
      ",\n",
      "'structur\n",
      "'\n",
      ",\n",
      "'guidelin\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'thi\n",
      "'\n",
      ",\n",
      "'encourag\n",
      "'\n",
      ",\n",
      "'volunt\n",
      "'\n",
      ",\n",
      "'proactiv\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'fulli\n",
      "'\n",
      ",\n",
      "'show\n",
      "'\n",
      ",\n",
      "'expertis\n",
      "'\n",
      ",\n",
      "'dynam\n",
      "'\n",
      ",\n",
      "'\n",
      "‘\n",
      "'\n",
      ",\n",
      "'open\n",
      "'\n",
      ",\n",
      "'discuss\n",
      "'\n",
      ",\n",
      "'session\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'compar\n",
      "'\n",
      ",\n",
      "'ksasf\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'becam\n",
      "'\n",
      ",\n",
      "'color\n",
      "'\n",
      ",\n",
      "'unpredict\n",
      "'\n",
      ",\n",
      "'micro-level\n",
      "'\n",
      ",\n",
      "'interactions—on\n",
      "'\n",
      ",\n",
      "'topic\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'doe\n",
      "'\n",
      ",\n",
      "'scienc\n",
      "'\n",
      ",\n",
      "'make\n",
      "'\n",
      ",\n",
      "'world\n",
      "'\n",
      ",\n",
      "'better\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'initi\n",
      "'\n",
      ",\n",
      "'casual\n",
      "'\n",
      ",\n",
      "'convers\n",
      "'\n",
      ",\n",
      "'volunt\n",
      "'\n",
      ",\n",
      "'particip\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'feel\n",
      "''\n",
      ",\n",
      "'power\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'theori\n",
      "'\n",
      ",\n",
      "'real-lif\n",
      "'\n",
      ",\n",
      "'exercis\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'could\n",
      "'\n",
      ",\n",
      "'embrac\n",
      "'\n",
      ",\n",
      "'core\n",
      "'\n",
      ",\n",
      "'idea\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'account\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'interact\n",
      "'\n",
      ",\n",
      "'everi\n",
      "'\n",
      ",\n",
      "'millisecond\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'regardless\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'believ\n",
      "'\n",
      ",\n",
      "'may\n",
      "'\n",
      ",\n",
      "'find\n",
      "'\n",
      ",\n",
      "'way\n",
      "'\n",
      ",\n",
      "'grasp\n",
      "'\n",
      ",\n",
      "'complex\n",
      "'\n",
      ",\n",
      "'world\n",
      "'\n",
      ",\n",
      "'embrac\n",
      "'\n",
      ",\n",
      "'limit\n",
      "'\n",
      ",\n",
      "'humbl\n",
      "'\n",
      ",\n",
      "'accept\n",
      "'\n",
      ",\n",
      "'uncontrol\n",
      "'\n",
      ",\n",
      "'versatil\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'from\n",
      "'\n",
      ",\n",
      "'scientist\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'viewpoint\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'may\n",
      "'\n",
      ",\n",
      "'sound\n",
      "'\n",
      ",\n",
      "'iron\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'still\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'theori\n",
      "'\n",
      ",\n",
      "'taught\n",
      "'\n",
      ",\n",
      "'gaze\n",
      "'\n",
      ",\n",
      "'upon\n",
      "'\n",
      ",\n",
      "'bigger\n",
      "'\n",
      ",\n",
      "'pictur\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'observ\n",
      "'\n",
      ",\n",
      "'frame\n",
      "'\n",
      ",\n",
      "'connect\n",
      "'\n",
      ",\n",
      "'see\n",
      "'\n",
      ",\n",
      "'true\n",
      "'\n",
      ",\n",
      "'mean\n",
      "'\n",
      ",\n",
      "'embed\n",
      "'\n",
      ",\n",
      "'behind\n",
      "'\n",
      ",\n",
      "'complex\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'dure\n",
      "''\n",
      ",\n",
      "'statist\n",
      "'\n",
      ",\n",
      "'physic\n",
      "'\n",
      ",\n",
      "'\n",
      "(\n",
      "'\n",
      ",\n",
      "'ph\n",
      "'\n",
      ",\n",
      "'\n",
      ")\n",
      "'\n",
      ",\n",
      "'class\n",
      "'\n",
      ",\n",
      "'kaist\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'professor\n",
      "'\n",
      ",\n",
      "'ask\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'knew\n",
      "'\n",
      ",\n",
      "'concept\n",
      "'\n",
      ",\n",
      "'ensembl\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'after\n",
      "'\n",
      ",\n",
      "'share\n",
      "'\n",
      ",\n",
      "'experi\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'warmli\n",
      "'\n",
      ",\n",
      "'smile\n",
      "'\n",
      ",\n",
      "'said\n",
      "'\n",
      ",\n",
      "'\n",
      ":\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'good\n",
      "'\n",
      ",\n",
      "'start\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "''\n",
      "''\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      "]\n",
      "'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer= PorterStemmer()\n",
    "input_str= str(result)\n",
    "input_str=word_tokenize(input_str)\n",
    "for word in input_str:\n",
    "    print(stemmer.stem(word))\n",
    "\n",
    "#tokenized_text = text_tokenizing(cleaned_text)\n",
    "#print(\"\\n형태소 분석 : \", tokenized_text)\n",
    "# text_input.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "'\n",
      "[\n",
      "'\n",
      ",\n",
      "``\n",
      "'Statistical\n",
      "''\n",
      ",\n",
      "'Physics\n",
      "'\n",
      ",\n",
      "'comedy\n",
      "'\n",
      ",\n",
      "'long-shot\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Professor\n",
      "'\n",
      ",\n",
      "'Nir\n",
      "'\n",
      ",\n",
      "'Gov\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'lecture\n",
      "'\n",
      ",\n",
      "'\n",
      "(\n",
      "'\n",
      ",\n",
      "'held\n",
      "'\n",
      ",\n",
      "'summer\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'Weizmann\n",
      "'\n",
      ",\n",
      "'Institute\n",
      "'\n",
      ",\n",
      "'Science\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'Israel\n",
      "'\n",
      ",\n",
      "'\n",
      ")\n",
      "'\n",
      ",\n",
      "'covered\n",
      "'\n",
      ",\n",
      "'single\n",
      "'\n",
      ",\n",
      "'topic\n",
      "'\n",
      ",\n",
      "'physics\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'However\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'application\n",
      "'\n",
      ",\n",
      "'truly\n",
      "'\n",
      ",\n",
      "'versatile—from\n",
      "'\n",
      ",\n",
      "'cell\n",
      "'\n",
      ",\n",
      "'dynamics\n",
      "'\n",
      ",\n",
      "'collaboration\n",
      "'\n",
      ",\n",
      "'patterns\n",
      "'\n",
      ",\n",
      "'ants\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Full\n",
      "'\n",
      ",\n",
      "'curiosity\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'approached\n",
      "'\n",
      ",\n",
      "'lecture\n",
      "'\n",
      ",\n",
      "'asked\n",
      "'\n",
      ",\n",
      "'learn\n",
      "'\n",
      ",\n",
      "'magical\n",
      "'\n",
      ",\n",
      "'tool\n",
      "'\n",
      ",\n",
      "'known\n",
      "'\n",
      ",\n",
      "'Statistical\n",
      "'\n",
      ",\n",
      "'Physics\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      "“\n",
      "'\n",
      ",\n",
      "'Start\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'theory\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "”\n",
      "'\n",
      ",\n",
      "'advised\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'Though\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'Statistical\n",
      "'\n",
      ",\n",
      "'Physics\n",
      "'\n",
      ",\n",
      "'seemed\n",
      "'\n",
      ",\n",
      "'tragedy\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'seen\n",
      "'\n",
      ",\n",
      "'close-up\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Spending\n",
      "'\n",
      ",\n",
      "'weeks\n",
      "'\n",
      ",\n",
      "'several\n",
      "'\n",
      ",\n",
      "'textbooks\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'found\n",
      "'\n",
      ",\n",
      "'maze\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'To\n",
      "''\n",
      ",\n",
      "'understand\n",
      "'\n",
      ",\n",
      "'system\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'shall\n",
      "'\n",
      ",\n",
      "'calculate\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'component\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'behavior\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'This\n",
      "'\n",
      ",\n",
      "'commandment\n",
      "'\n",
      ",\n",
      "'summarizes\n",
      "'\n",
      ",\n",
      "'physics\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'learned\n",
      "'\n",
      ",\n",
      "'three\n",
      "'\n",
      ",\n",
      "'years\n",
      "'\n",
      ",\n",
      "'Korea\n",
      "'\n",
      ",\n",
      "'Science\n",
      "'\n",
      ",\n",
      "'Academy\n",
      "'\n",
      ",\n",
      "'\n",
      "(\n",
      "'\n",
      ",\n",
      "'KSA\n",
      "'\n",
      ",\n",
      "'\n",
      ")\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'However\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'consider\n",
      "'\n",
      ",\n",
      "'system\n",
      "'\n",
      ",\n",
      "'myriad\n",
      "'\n",
      ",\n",
      "'particles\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'directive\n",
      "'\n",
      ",\n",
      "'defied\n",
      "'\n",
      ",\n",
      "'virtual\n",
      "'\n",
      ",\n",
      "'impossibility\n",
      "'\n",
      ",\n",
      "'figuring\n",
      "'\n",
      ",\n",
      "'motions\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'particle\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Instead\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'physicists\n",
      "'\n",
      ",\n",
      "'construct\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'macroscopic\n",
      "'\n",
      ",\n",
      "'snapshots\n",
      "'\n",
      ",\n",
      "'system\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'The\n",
      "'\n",
      ",\n",
      "'snapshots\n",
      "'\n",
      ",\n",
      "'contain\n",
      "'\n",
      ",\n",
      "'different\n",
      "'\n",
      ",\n",
      "'particle\n",
      "'\n",
      ",\n",
      "'arrangements\n",
      "'\n",
      ",\n",
      "'movements\n",
      "'\n",
      ",\n",
      "'\n",
      "“\n",
      "'\n",
      ",\n",
      "'collection\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "”\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'As\n",
      "''\n",
      ",\n",
      "'far\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'understood\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'theory\n",
      "'\n",
      ",\n",
      "'similar\n",
      "'\n",
      ",\n",
      "'understanding\n",
      "'\n",
      ",\n",
      "'theme\n",
      "'\n",
      ",\n",
      "'movie\n",
      "'\n",
      ",\n",
      "'watching\n",
      "'\n",
      ",\n",
      "'preview\n",
      "'\n",
      ",\n",
      "'consists\n",
      "'\n",
      ",\n",
      "'important\n",
      "'\n",
      ",\n",
      "'scenes\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Hypothetically\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'analyze\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'actor\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'line\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'frame\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'would\n",
      "'\n",
      ",\n",
      "'actually\n",
      "'\n",
      ",\n",
      "'hinder\n",
      "'\n",
      ",\n",
      "'grasping\n",
      "'\n",
      ",\n",
      "'overall\n",
      "'\n",
      ",\n",
      "'message\n",
      "'\n",
      ",\n",
      "'film\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'In\n",
      "'\n",
      ",\n",
      "'short\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'theory\n",
      "'\n",
      ",\n",
      "'states\n",
      "'\n",
      ",\n",
      "'state\n",
      "'\n",
      ",\n",
      "'matter\n",
      "'\n",
      ",\n",
      "'understood\n",
      "'\n",
      ",\n",
      "'without\n",
      "'\n",
      ",\n",
      "'knowing\n",
      "'\n",
      ",\n",
      "'movements\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'particle\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'At\n",
      "'\n",
      ",\n",
      "'odds\n",
      "'\n",
      ",\n",
      "'existing\n",
      "'\n",
      ",\n",
      "'beliefs\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'new\n",
      "'\n",
      ",\n",
      "'approach\n",
      "'\n",
      ",\n",
      "'refused\n",
      "'\n",
      ",\n",
      "'settle\n",
      "'\n",
      ",\n",
      "'brain\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Even\n",
      "'\n",
      ",\n",
      "'well-designed\n",
      "'\n",
      ",\n",
      "'exercise\n",
      "'\n",
      ",\n",
      "'problems\n",
      "'\n",
      ",\n",
      "'textbooks\n",
      "'\n",
      ",\n",
      "'could\n",
      "'\n",
      ",\n",
      "'save\n",
      "'\n",
      ",\n",
      "'drowning\n",
      "'\n",
      ",\n",
      "'confusion\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'Meanwhile\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'theory\n",
      "'\n",
      ",\n",
      "'suggested\n",
      "'\n",
      ",\n",
      "'possible\n",
      "'\n",
      ",\n",
      "'explanation\n",
      "'\n",
      ",\n",
      "'unanswered\n",
      "'\n",
      ",\n",
      "'questions\n",
      "'\n",
      ",\n",
      "'leadership\n",
      "'\n",
      ",\n",
      "'KSA\n",
      "'\n",
      ",\n",
      "'Science\n",
      "'\n",
      ",\n",
      "'Fair\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'To\n",
      "'\n",
      ",\n",
      "'successfully\n",
      "'\n",
      ",\n",
      "'manage\n",
      "'\n",
      ",\n",
      "'KSA\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'largest\n",
      "'\n",
      ",\n",
      "'international\n",
      "'\n",
      ",\n",
      "'festival\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'provided\n",
      "'\n",
      ",\n",
      "'detailed\n",
      "'\n",
      ",\n",
      "'instructions\n",
      "'\n",
      ",\n",
      "'volunteer\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'For\n",
      "'\n",
      ",\n",
      "'example\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'assigned\n",
      "'\n",
      ",\n",
      "'fifteen\n",
      "'\n",
      ",\n",
      "'volunteers\n",
      "'\n",
      ",\n",
      "'specific\n",
      "'\n",
      ",\n",
      "'task\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'like\n",
      "'\n",
      ",\n",
      "'placement\n",
      "'\n",
      ",\n",
      "'posters\n",
      "'\n",
      ",\n",
      "'strict\n",
      "'\n",
      ",\n",
      "'discussion\n",
      "'\n",
      ",\n",
      "'guidelines\n",
      "'\n",
      ",\n",
      "'sessions\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'start\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'presentation\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Despite\n",
      "'\n",
      ",\n",
      "'efforts\n",
      "'\n",
      ",\n",
      "'trying\n",
      "'\n",
      ",\n",
      "'control\n",
      "'\n",
      ",\n",
      "'aspects\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'problems\n",
      "'\n",
      ",\n",
      "'emerged\n",
      "'\n",
      ",\n",
      "'volunteers\n",
      "'\n",
      ",\n",
      "'starting\n",
      "'\n",
      ",\n",
      "'miss\n",
      "'\n",
      ",\n",
      "'detailed\n",
      "'\n",
      ",\n",
      "'plan\n",
      "'\n",
      ",\n",
      "'action\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Initially\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'clueless\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'tried\n",
      "'\n",
      ",\n",
      "'understand\n",
      "'\n",
      ",\n",
      "'detailed\n",
      "'\n",
      ",\n",
      "'plan\n",
      "'\n",
      ",\n",
      "'execution\n",
      "'\n",
      ",\n",
      "'could\n",
      "'\n",
      ",\n",
      "'go\n",
      "'\n",
      ",\n",
      "'haywire\n",
      "'\n",
      ",\n",
      "'\n",
      ";\n",
      "'\n",
      ",\n",
      "'however\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'knowledge\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'theory\n",
      "'\n",
      ",\n",
      "'deepened\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'began\n",
      "'\n",
      ",\n",
      "'realize\n",
      "'\n",
      ",\n",
      "'fundamental\n",
      "'\n",
      ",\n",
      "'problems\n",
      "'\n",
      ",\n",
      "'rooted\n",
      "'\n",
      ",\n",
      "'approach\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'Instead\n",
      "''\n",
      ",\n",
      "'micromanagement\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'viewed\n",
      "'\n",
      ",\n",
      "'KSASF\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'seen\n",
      "'\n",
      ",\n",
      "'bigger\n",
      "'\n",
      ",\n",
      "'picture\n",
      "'\n",
      ",\n",
      "'KSASF\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'As\n",
      "'\n",
      ",\n",
      "'head\n",
      "'\n",
      ",\n",
      "'volunteer\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'brave\n",
      "'\n",
      ",\n",
      "'enough\n",
      "'\n",
      ",\n",
      "'take\n",
      "'\n",
      ",\n",
      "'step\n",
      "'\n",
      ",\n",
      "'back\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'observe\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'created\n",
      "'\n",
      ",\n",
      "'macroscopic\n",
      "'\n",
      ",\n",
      "'background\n",
      "'\n",
      ",\n",
      "'honors\n",
      "'\n",
      ",\n",
      "'core\n",
      "'\n",
      ",\n",
      "'essence\n",
      "'\n",
      ",\n",
      "'KSASF—the\n",
      "'\n",
      ",\n",
      "'exchange\n",
      "'\n",
      ",\n",
      "'scientific\n",
      "'\n",
      ",\n",
      "'ideas\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'Given\n",
      "''\n",
      ",\n",
      "'second\n",
      "'\n",
      ",\n",
      "'chance\n",
      "'\n",
      ",\n",
      "'head\n",
      "'\n",
      ",\n",
      "'volunteer\n",
      "'\n",
      ",\n",
      "'KSA\n",
      "'\n",
      ",\n",
      "'Youth\n",
      "'\n",
      ",\n",
      "'Science\n",
      "'\n",
      ",\n",
      "'Camp\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'mentoring\n",
      "'\n",
      ",\n",
      "'event\n",
      "'\n",
      ",\n",
      "'sixty\n",
      "'\n",
      ",\n",
      "'elementary\n",
      "'\n",
      ",\n",
      "'middle\n",
      "'\n",
      ",\n",
      "'school\n",
      "'\n",
      ",\n",
      "'students\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'envisioned\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'activities\n",
      "'\n",
      ",\n",
      "'perspective\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'event\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'align\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'core\n",
      "'\n",
      ",\n",
      "'message—learning\n",
      "'\n",
      ",\n",
      "'science\n",
      "'\n",
      ",\n",
      "'inquiries\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'designed\n",
      "'\n",
      ",\n",
      "'events\n",
      "'\n",
      ",\n",
      "'macroscopic\n",
      "'\n",
      ",\n",
      "'thinking\n",
      "'\n",
      ",\n",
      "'\n",
      ":\n",
      "'\n",
      ",\n",
      "'relevant\n",
      "'\n",
      ",\n",
      "'given\n",
      "'\n",
      ",\n",
      "'theme\n",
      "'\n",
      ",\n",
      "'minimizing\n",
      "'\n",
      ",\n",
      "'structure\n",
      "'\n",
      ",\n",
      "'guidelines\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'This\n",
      "'\n",
      ",\n",
      "'encouraged\n",
      "'\n",
      ",\n",
      "'volunteers\n",
      "'\n",
      ",\n",
      "'proactive\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'fully\n",
      "'\n",
      ",\n",
      "'showing\n",
      "'\n",
      ",\n",
      "'expertise\n",
      "'\n",
      ",\n",
      "'dynamic\n",
      "'\n",
      ",\n",
      "'\n",
      "‘\n",
      "'\n",
      ",\n",
      "'open\n",
      "'\n",
      ",\n",
      "'discussion\n",
      "'\n",
      ",\n",
      "'sessions\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'Compared\n",
      "'\n",
      ",\n",
      "'KSASF\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'camp\n",
      "'\n",
      ",\n",
      "'became\n",
      "'\n",
      ",\n",
      "'colorful\n",
      "'\n",
      ",\n",
      "'unpredictable\n",
      "'\n",
      ",\n",
      "'micro-level\n",
      "'\n",
      ",\n",
      "'interactions—one\n",
      "'\n",
      ",\n",
      "'topics\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'Does\n",
      "'\n",
      ",\n",
      "'science\n",
      "'\n",
      ",\n",
      "'make\n",
      "'\n",
      ",\n",
      "'world\n",
      "'\n",
      ",\n",
      "'better\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'initiated\n",
      "'\n",
      ",\n",
      "'casual\n",
      "'\n",
      ",\n",
      "'conversation\n",
      "'\n",
      ",\n",
      "'volunteer\n",
      "'\n",
      ",\n",
      "'participants\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'Feeling\n",
      "''\n",
      ",\n",
      "'power\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'theory\n",
      "'\n",
      ",\n",
      "'real-life\n",
      "'\n",
      ",\n",
      "'exercise\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'could\n",
      "'\n",
      ",\n",
      "'embrace\n",
      "'\n",
      ",\n",
      "'core\n",
      "'\n",
      ",\n",
      "'idea\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'account\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'interaction\n",
      "'\n",
      ",\n",
      "'every\n",
      "'\n",
      ",\n",
      "'millisecond\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Regardless\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'believe\n",
      "'\n",
      ",\n",
      "'may\n",
      "'\n",
      ",\n",
      "'find\n",
      "'\n",
      ",\n",
      "'ways\n",
      "'\n",
      ",\n",
      "'grasp\n",
      "'\n",
      ",\n",
      "'complexity\n",
      "'\n",
      ",\n",
      "'world\n",
      "'\n",
      ",\n",
      "'embracing\n",
      "'\n",
      ",\n",
      "'limitations\n",
      "'\n",
      ",\n",
      "'humbly\n",
      "'\n",
      ",\n",
      "'accepting\n",
      "'\n",
      ",\n",
      "'uncontrollable\n",
      "'\n",
      ",\n",
      "'versatility\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'From\n",
      "'\n",
      ",\n",
      "'scientist\n",
      "'\n",
      ",\n",
      "'\n",
      "’\n",
      "'\n",
      ",\n",
      "'viewpoint\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'may\n",
      "'\n",
      ",\n",
      "'sound\n",
      "'\n",
      ",\n",
      "'ironic\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'Still\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'theory\n",
      "'\n",
      ",\n",
      "'taught\n",
      "'\n",
      ",\n",
      "'gaze\n",
      "'\n",
      ",\n",
      "'upon\n",
      "'\n",
      ",\n",
      "'bigger\n",
      "'\n",
      ",\n",
      "'picture\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'observe\n",
      "'\n",
      ",\n",
      "'frames\n",
      "'\n",
      ",\n",
      "'connect\n",
      "'\n",
      ",\n",
      "'see\n",
      "'\n",
      ",\n",
      "'true\n",
      "'\n",
      ",\n",
      "'meaning\n",
      "'\n",
      ",\n",
      "'embedded\n",
      "'\n",
      ",\n",
      "'behind\n",
      "'\n",
      ",\n",
      "'complexity\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "``\n",
      "'During\n",
      "''\n",
      ",\n",
      "'Statistical\n",
      "'\n",
      ",\n",
      "'Physics\n",
      "'\n",
      ",\n",
      "'\n",
      "(\n",
      "'\n",
      ",\n",
      "'PH\n",
      "'\n",
      ",\n",
      "'\n",
      ")\n",
      "'\n",
      ",\n",
      "'class\n",
      "'\n",
      ",\n",
      "'KAIST\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'professor\n",
      "'\n",
      ",\n",
      "'asked\n",
      "'\n",
      ",\n",
      "'\n",
      "I\n",
      "'\n",
      ",\n",
      "'knew\n",
      "'\n",
      ",\n",
      "'concept\n",
      "'\n",
      ",\n",
      "'ensemble\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "'After\n",
      "'\n",
      ",\n",
      "'sharing\n",
      "'\n",
      ",\n",
      "'experiences\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'\n",
      ",\n",
      "'warmly\n",
      "'\n",
      ",\n",
      "'smiled\n",
      "'\n",
      ",\n",
      "'said\n",
      "'\n",
      ",\n",
      "'\n",
      ":\n",
      "'\n",
      ",\n",
      "'\n",
      "``\n",
      "'\n",
      ",\n",
      "'Good\n",
      "'\n",
      ",\n",
      "'start\n",
      "'\n",
      ",\n",
      "'\n",
      ".\n",
      "'\n",
      ",\n",
      "``\n",
      "''\n",
      "''\n",
      ",\n",
      "``\n",
      "'\n",
      "''\n",
      ",\n",
      "'\n",
      "]\n",
      "'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "input_str=str(result)\n",
    "input_str=word_tokenize(input_str)\n",
    "for word in input_str:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of speech tagging (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'NN'), ('[', 'NNP'), (\"'\", 'POS'), (\"'Statistical\", 'JJ'), (\"'Physics\", 'NNS'), (\"'\", 'POS'), (\"'comedy\", 'NNP'), (\"'\", 'POS'), (\"'long-shot\", 'JJ'), (\"'Professor\", 'NNP'), (\"'\", 'POS'), (\"'Nir\", 'NNP'), (\"'\", 'POS'), (\"'Gov\", 'NNP'), (\"'\", 'POS'), ('’', 'NNP'), (\"'\", 'POS'), (\"'lecture\", 'NN'), (\"'held\", 'NNP'), (\"'\", 'POS'), (\"'camp\", 'NNP'), (\"'\", 'POS'), (\"'Weizmann\", 'NNP'), (\"'\", 'POS'), (\"'Science\", 'NNP'), (\"'\", 'POS'), (\"'Israel\", 'NNP'), (\"'\", 'POS'), (\"'covered\", 'VBD'), (\"'single\", 'NNP'), (\"'\", 'POS'), (\"'topic\", 'NNP'), (\"'\", 'POS'), (\"'physics\", 'NNS'), (\"'\", 'POS'), (\"'application\", 'NNP'), (\"'\", 'POS'), (\"'truly\", 'NNP'), (\"'\", 'POS'), (\"'versatile—from\", 'IN'), (\"'cell\", 'NNP'), (\"'\", 'POS'), (\"'dynamics\", 'NNS'), (\"'\", 'POS'), (\"'collaboration\", 'NN'), (\"'patterns\", 'NNS'), (\"'\", 'POS'), (\"'ants\", 'NNS'), (\"'\", 'POS'), (\"'Full\", 'NNP'), (\"'\", 'POS'), (\"'curiosity\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'approached\", 'VBD'), (\"'lecture\", 'NN'), (\"'asked\", 'VBD'), (\"'learn\", 'NNP'), (\"'\", 'POS'), (\"'magical\", 'JJ'), (\"'tool\", 'NNP'), (\"'\", 'POS'), (\"'Statistical\", 'JJ'), (\"'Physics\", 'NNS'), (\"'\", 'POS'), ('“', 'NNP'), (\"'\", 'POS'), (\"'Start\", 'NNP'), (\"'\", 'POS'), (\"'ensemble\", 'JJ'), (\"'theory\", 'NNP'), (\"'\", 'POS'), ('”', 'NNP'), (\"'\", 'POS'), (\"'advised\", 'VBD'), (\"'Though\", 'IN'), (\"'Statistical\", 'JJ'), (\"'Physics\", 'NNS'), (\"'\", 'POS'), (\"'seemed\", 'VBD'), (\"'tragedy\", 'NNP'), (\"'\", 'POS'), (\"'close-up\", 'NNP'), (\"'\", 'POS'), (\"'Spending\", 'VBG'), (\"'several\", 'NNP'), (\"'\", 'POS'), (\"'textbooks\", 'NNS'), (\"'\", 'POS'), ('I', 'PRP'), (\"'found\", 'IN'), (\"'maze\", 'NNP'), (\"'\", 'POS'), (\"'understand\", 'NNP'), (\"'\", 'POS'), (\"'system\", 'NNP'), (\"'\", 'POS'), (\"'shall\", 'DT'), (\"'calculate\", 'NNP'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'component\", 'NNP'), (\"'\", 'POS'), ('’', 'NNP'), (\"'\", 'POS'), (\"'behavior\", 'NNP'), (\"'\", 'POS'), (\"'This\", 'NNP'), (\"'\", 'POS'), (\"'commandment\", 'NNP'), (\"'\", 'POS'), (\"'summarizes\", 'VBZ'), (\"'\", 'POS'), (\"'physics\", 'NNS'), (\"'\", 'POS'), ('I', 'PRP'), (\"'learned\", 'VBD'), (\"'years\", 'NNS'), (\"'\", 'POS'), (\"'Science\", 'NNP'), (\"'\", 'POS'), (\"'Academy\", 'NNP'), (\"'\", 'POS'), (\"'KSA\", 'NNP'), (\"'\", 'POS'), (\"'system\", 'NNP'), (\"'\", 'POS'), (\"'myriad\", 'NNP'), (\"'\", 'POS'), (\"'particles\", 'NNS'), (\"'\", 'POS'), (\"'directive\", 'CD'), (\"'defied\", 'VBD'), (\"'virtual\", 'JJ'), (\"'impossibility\", 'NNP'), (\"'\", 'POS'), (\"'figuring\", 'VBG'), (\"'motions\", 'NNS'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'particle\", 'NNP'), (\"'\", 'POS'), (\"'physicists\", 'NNS'), (\"'\", 'POS'), (\"'construct\", 'NN'), (\"'ensemble\", 'JJ'), (\"'macroscopic\", 'NNP'), (\"'\", 'POS'), (\"'snapshots\", 'NNS'), (\"'\", 'POS'), (\"'system\", 'NNP'), (\"'\", 'POS'), (\"'The\", 'NNP'), (\"'\", 'POS'), (\"'snapshots\", 'NNS'), (\"'\", 'POS'), (\"'different\", 'NNP'), (\"'\", 'POS'), (\"'particle\", 'NNP'), (\"'\", 'POS'), (\"'arrangements\", 'NNS'), (\"'\", 'POS'), (\"'movements\", 'NNS'), (\"'\", 'POS'), ('“', 'NNP'), (\"'\", 'POS'), (\"'collection\", 'NN'), ('”', 'NNP'), (\"'\", 'POS'), (\"'far\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'understood\", 'NNP'), (\"'\", 'POS'), (\"'ensemble\", 'JJ'), (\"'theory\", 'NNP'), (\"'\", 'POS'), (\"'understanding\", 'VBG'), (\"'movie\", 'NNP'), (\"'\", 'POS'), (\"'watching\", 'VBG'), (\"'preview\", 'NNP'), (\"'\", 'POS'), (\"'consists\", 'NNS'), (\"'\", 'POS'), (\"'important\", 'NNP'), (\"'\", 'POS'), (\"'scenes\", 'NNS'), (\"'\", 'POS'), (\"'Hypothetically\", 'RB'), ('I', 'PRP'), (\"'analyze\", 'NNP'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'actor\", 'NNP'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'line\", 'NNP'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'would\", 'MD'), (\"'actually\", 'RB'), (\"'\", 'POS'), (\"'grasping\", 'VBG'), (\"'overall\", 'DT'), (\"'message\", 'NN'), (\"'film\", 'NNP'), (\"'\", 'POS'), (\"'In\", 'NNP'), (\"'\", 'POS'), (\"'short\", 'NNP'), (\"'\", 'POS'), (\"'theory\", 'NNP'), (\"'\", 'POS'), (\"'states\", 'NNS'), (\"'\", 'POS'), (\"'state\", 'NNP'), (\"'\", 'POS'), (\"'matter\", 'NNP'), (\"'\", 'POS'), (\"'understood\", 'NNP'), (\"'\", 'POS'), (\"'without\", 'IN'), (\"'knowing\", 'VBG'), (\"'movements\", 'NNS'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'particle\", 'NNP'), (\"'\", 'POS'), (\"'At\", 'NNP'), (\"'\", 'POS'), (\"'odds\", 'NNS'), (\"'\", 'POS'), (\"'existing\", 'VBG'), (\"'new\", 'NNP'), (\"'\", 'POS'), (\"'approach\", 'NNP'), (\"'\", 'POS'), (\"'refused\", 'VBD'), (\"'settle\", 'NNP'), (\"'\", 'POS'), (\"'well-designed\", 'JJ'), (\"'exercise\", 'NNP'), (\"'\", 'POS'), (\"'problems\", 'NNS'), (\"'\", 'POS'), (\"'textbooks\", 'NNS'), (\"'\", 'POS'), (\"'could\", 'MD'), (\"'save\", 'NNP'), (\"'\", 'POS'), (\"'drowning\", 'VBG'), (\"'confusion\", 'NNP'), (\"'\", 'POS'), (\"'Meanwhile\", 'NN'), (\"'ensemble\", 'JJ'), (\"'theory\", 'NNP'), (\"'\", 'POS'), (\"'suggested\", 'VBD'), (\"'possible\", 'JJ'), (\"'explanation\", 'NNP'), (\"'\", 'POS'), (\"'unanswered\", 'VBD'), (\"'questions\", 'NNS'), (\"'\", 'POS'), (\"'KSA\", 'NNP'), (\"'\", 'POS'), (\"'Science\", 'NN'), (\"'Fair\", 'NNP'), (\"'\", 'POS'), (\"'To\", 'NNP'), (\"'\", 'POS'), (\"'successfully\", 'RB'), (\"'\", 'POS'), (\"'manage\", 'NN'), (\"'KSA\", 'NNP'), (\"'\", 'POS'), ('’', 'NNP'), (\"'\", 'POS'), (\"'largest\", 'JJS'), (\"'international\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'provided\", 'VBD'), (\"'detailed\", 'VBD'), (\"'instructions\", 'NNS'), (\"'\", 'POS'), (\"'volunteer\", 'NNP'), (\"'\", 'POS'), (\"'For\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'assigned\", 'VBD'), (\"'volunteers\", 'NNS'), (\"'\", 'POS'), (\"'specific\", 'NNP'), (\"'\", 'POS'), (\"'task\", 'NNP'), (\"'\", 'POS'), (\"'like\", 'IN'), (\"'placement\", 'NNP'), (\"'\", 'POS'), (\"'posters\", 'NNS'), (\"'\", 'POS'), (\"'strict\", 'NNP'), (\"'\", 'POS'), (\"'discussion\", 'NN'), (\"'guidelines\", 'NNS'), (\"'\", 'POS'), (\"'sessions\", 'NNS'), (\"'\", 'POS'), (\"'start\", 'NNP'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'presentation\", 'NN'), (\"'Despite\", 'NNP'), (\"'\", 'POS'), (\"'efforts\", 'NNS'), (\"'\", 'POS'), (\"'trying\", 'VBG'), (\"'control\", 'NNP'), (\"'\", 'POS'), (\"'aspects\", 'NNS'), (\"'\", 'POS'), (\"'problems\", 'VBZ'), (\"'\", 'POS'), (\"'emerged\", 'VBD'), (\"'volunteers\", 'NNS'), (\"'\", 'POS'), (\"'starting\", 'VBG'), (\"'detailed\", 'VBD'), (\"'plan\", 'NNP'), (\"'\", 'POS'), (\"'action\", 'NN'), (\"'Initially\", 'RB'), ('I', 'PRP'), (\"'clueless\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'tried\", 'VBD'), (\"'understand\", 'NNP'), (\"'\", 'POS'), (\"'detailed\", 'VBD'), (\"'plan\", 'NNP'), (\"'\", 'POS'), (\"'execution\", 'NN'), (\"'could\", 'MD'), (\"'go\", 'NNP'), (\"'\", 'POS'), (\"'haywire\", 'NNP'), (\"'\", 'POS'), (\"'knowledge\", 'NNP'), (\"'\", 'POS'), (\"'ensemble\", 'JJ'), (\"'theory\", 'NNP'), (\"'\", 'POS'), (\"'deepened\", 'VBD'), ('I', 'PRP'), (\"'began\", 'NNP'), (\"'\", 'POS'), (\"'fundamental\", 'NNP'), (\"'\", 'POS'), (\"'problems\", 'NNS'), (\"'\", 'POS'), (\"'rooted\", 'VBD'), (\"'approach\", 'NNP'), (\"'\", 'POS'), (\"'Instead\", 'NN'), (\"'micromanagement\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'viewed\", 'VBD'), (\"'KSASF\", 'NNP'), (\"'\", 'POS'), (\"'ensemble\", 'JJ'), (\"'bigger\", 'NNP'), (\"'\", 'POS'), (\"'picture\", 'NN'), (\"'KSASF\", 'NNP'), (\"'\", 'POS'), (\"'As\", 'NNP'), (\"'\", 'POS'), (\"'volunteer\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'brave\", 'NNP'), (\"'\", 'POS'), (\"'enough\", 'IN'), (\"'take\", 'NNP'), (\"'\", 'POS'), (\"'observe\", 'NNP'), (\"'\", 'POS'), (\"'created\", 'VBD'), (\"'macroscopic\", 'NNP'), (\"'\", 'POS'), (\"'background\", 'IN'), (\"'honors\", 'NNS'), (\"'\", 'POS'), (\"'essence\", 'NNP'), (\"'\", 'POS'), (\"'KSASF—the\", 'NNP'), (\"'\", 'POS'), (\"'exchange\", 'NNP'), (\"'\", 'POS'), (\"'scientific\", 'NNP'), (\"'\", 'POS'), (\"'ideas\", 'NNS'), (\"'\", 'POS'), (\"'second\", 'NNP'), (\"'\", 'POS'), (\"'chance\", 'NN'), (\"'volunteer\", 'NNP'), (\"'\", 'POS'), (\"'KSA\", 'NNP'), (\"'\", 'POS'), (\"'Youth\", 'NNP'), (\"'\", 'POS'), (\"'Science\", 'NN'), (\"'Camp\", 'NNP'), (\"'\", 'POS'), (\"'mentoring\", 'VBG'), (\"'event\", 'NNP'), (\"'\", 'POS'), (\"'elementary\", 'NNP'), (\"'\", 'POS'), (\"'middle\", 'NNP'), (\"'\", 'POS'), (\"'school\", 'NNP'), (\"'\", 'POS'), (\"'students\", 'NNS'), (\"'\", 'POS'), ('I', 'PRP'), (\"'envisioned\", 'VBD'), (\"'camp\", 'NNP'), (\"'\", 'POS'), ('’', 'NNP'), (\"'\", 'POS'), (\"'activities\", 'NNS'), (\"'\", 'POS'), (\"'perspective\", 'CD'), (\"'ensemble\", 'JJ'), (\"'event\", 'NNP'), (\"'\", 'POS'), (\"'camp\", 'NNP'), (\"'\", 'POS'), (\"'align\", 'NNP'), (\"'\", 'POS'), (\"'camp\", 'NNP'), (\"'\", 'POS'), ('’', 'NNP'), (\"'\", 'POS'), (\"'message—learning\", 'VBG'), (\"'science\", 'NNP'), (\"'\", 'POS'), (\"'inquiries\", 'NNS'), (\"'\", 'POS'), ('I', 'PRP'), (\"'designed\", 'VBD'), (\"'events\", 'NNS'), (\"'\", 'POS'), (\"'macroscopic\", 'NNP'), (\"'\", 'POS'), (\"'thinking\", 'VBG'), (\"'relevant\", 'NNP'), (\"'\", 'POS'), (\"'minimizing\", 'VBG'), (\"'structure\", 'NN'), (\"'guidelines\", 'NNS'), (\"'\", 'POS'), (\"'This\", 'NNP'), (\"'\", 'POS'), (\"'encouraged\", 'VBD'), (\"'volunteers\", 'NNS'), (\"'\", 'POS'), (\"'proactive\", 'CD'), (\"'fully\", 'RB'), (\"'\", 'POS'), (\"'showing\", 'VBG'), (\"'expertise\", 'NNP'), (\"'\", 'POS'), (\"'dynamic\", 'NNP'), (\"'\", 'POS'), ('‘', 'NNP'), (\"'\", 'POS'), (\"'open\", 'NNP'), (\"'\", 'POS'), (\"'discussion\", 'NN'), (\"'sessions\", 'NNS'), ('’', 'NNP'), (\"'\", 'POS'), (\"'Compared\", 'VBD'), (\"'KSASF\", 'NNP'), (\"'\", 'POS'), (\"'camp\", 'NNP'), (\"'\", 'POS'), (\"'unpredictable\", 'JJ'), (\"'micro-level\", 'JJ'), (\"'interactions—one\", 'CD'), (\"'topics\", 'NNS'), (\"'\", 'POS'), (\"'Does\", 'NNS'), (\"'\", 'POS'), (\"'science\", 'NN'), (\"'make\", 'NNP'), (\"'\", 'POS'), (\"'world\", 'NNP'), (\"'\", 'POS'), (\"'better\", 'NNP'), (\"'\", 'POS'), (\"'initiated\", 'VBD'), (\"'casual\", 'JJ'), (\"'conversation\", 'NNP'), (\"'\", 'POS'), (\"'volunteer\", 'NNP'), (\"'\", 'POS'), (\"'participants\", 'NNS'), (\"'\", 'POS'), (\"'Feeling\", 'VBG'), (\"'power\", 'NNP'), (\"'\", 'POS'), (\"'ensemble\", 'JJ'), (\"'theory\", 'NNP'), (\"'\", 'POS'), (\"'real-life\", 'JJ'), (\"'exercise\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'could\", 'MD'), (\"'embrace\", 'NNP'), (\"'\", 'POS'), (\"'idea\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'account\", 'NNP'), (\"'\", 'POS'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'interaction\", 'NN'), (\"'every\", 'NNP'), (\"'\", 'POS'), (\"'Regardless\", 'NNP'), (\"'\", 'POS'), ('I', 'PRP'), (\"'believe\", 'NNP'), (\"'\", 'POS'), (\"'may\", 'NNP'), (\"'\", 'POS'), (\"'find\", 'IN'), (\"'ways\", 'NNS'), (\"'\", 'POS'), (\"'grasp\", 'NNP'), (\"'\", 'POS'), (\"'complexity\", 'NNP'), (\"'\", 'POS'), (\"'world\", 'NNP'), (\"'\", 'POS'), (\"'embracing\", 'VBG'), (\"'limitations\", 'NNS'), (\"'\", 'POS'), (\"'humbly\", 'RB'), (\"'accepting\", 'VBG'), (\"'uncontrollable\", 'JJ'), (\"'versatility\", 'NNP'), (\"'\", 'POS'), (\"'From\", 'IN'), ('’', 'NNP'), (\"'\", 'POS'), (\"'viewpoint\", 'NNP'), (\"'\", 'POS'), (\"'may\", 'NNP'), (\"'\", 'POS'), (\"'sound\", 'IN'), (\"'ironic\", 'NNP'), (\"'\", 'POS'), (\"'Still\", 'NNP'), (\"'\", 'POS'), (\"'ensemble\", 'JJ'), (\"'theory\", 'NNP'), (\"'\", 'POS'), (\"'taught\", 'NNP'), (\"'\", 'POS'), (\"'gaze\", 'NNP'), (\"'\", 'POS'), (\"'bigger\", 'NNP'), (\"'\", 'POS'), (\"'picture\", 'NN'), (\"'observe\", 'NNP'), (\"'\", 'POS'), (\"'frames\", 'NNS'), (\"'\", 'POS'), (\"'connect\", 'NNP'), (\"'\", 'POS'), (\"'see\", 'NNP'), (\"'\", 'POS'), (\"'meaning\", 'VBG'), (\"'embedded\", 'VBD'), (\"'behind\", 'IN'), (\"'complexity\", 'NNP'), (\"'\", 'POS'), (\"'During\", 'VBG'), (\"'Statistical\", 'NNP'), (\"'\", 'POS'), (\"'Physics\", 'NNS'), (\"'\", 'POS'), (\"'PH\", 'NNP'), (\"'\", 'POS'), (\"'class\", 'NNP'), (\"'\", 'POS'), (\"'KAIST\", 'NNP'), (\"'\", 'POS'), (\"'professor\", 'NNP'), (\"'\", 'POS'), (\"'asked\", 'VBD'), ('I', 'PRP'), (\"'knew\", 'NNP'), (\"'\", 'POS'), (\"'concept\", 'IN'), (\"'ensemble\", 'JJ'), (\"'After\", 'NNP'), (\"'\", 'POS'), (\"'sharing\", 'VBG'), (\"'experiences\", 'NNS'), (\"'\", 'POS'), (\"'warmly\", 'NNP'), (\"'\", 'POS'), (\"'smiled\", 'VBD'), (\"'said\", 'NNP'), (\"'\", 'POS'), (\"'Good\", 'NNP'), (\"'\", 'POS'), (\"'start\", 'NNP'), (\"'\", 'POS'), (']', 'NNP'), (\"'\", 'POS'), (']', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "result = TextBlob(str(result))\n",
    "print(result.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP [/NN)\n",
      "  [/NNP\n",
      "  '/POS\n",
      "  'Statistical/JJ\n",
      "  'Physics/NNS\n",
      "  '/POS\n",
      "  'comedy/NNP\n",
      "  '/POS\n",
      "  'long-shot/JJ\n",
      "  'Professor/NNP\n",
      "  '/POS\n",
      "  'Nir/NNP\n",
      "  '/POS\n",
      "  'Gov/NNP\n",
      "  '/POS\n",
      "  ’/NNP\n",
      "  '/POS\n",
      "  (NP 'lecture/NN)\n",
      "  'held/NNP\n",
      "  '/POS\n",
      "  'camp/NNP\n",
      "  '/POS\n",
      "  'Weizmann/NNP\n",
      "  '/POS\n",
      "  'Science/NNP\n",
      "  '/POS\n",
      "  'Israel/NNP\n",
      "  '/POS\n",
      "  'covered/VBD\n",
      "  'single/NNP\n",
      "  '/POS\n",
      "  'topic/NNP\n",
      "  '/POS\n",
      "  'physics/NNS\n",
      "  '/POS\n",
      "  'application/NNP\n",
      "  '/POS\n",
      "  'truly/NNP\n",
      "  '/POS\n",
      "  'versatile—from/IN\n",
      "  'cell/NNP\n",
      "  '/POS\n",
      "  'dynamics/NNS\n",
      "  '/POS\n",
      "  (NP 'collaboration/NN)\n",
      "  'patterns/NNS\n",
      "  '/POS\n",
      "  'ants/NNS\n",
      "  '/POS\n",
      "  'Full/NNP\n",
      "  '/POS\n",
      "  'curiosity/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'approached/VBD\n",
      "  (NP 'lecture/NN)\n",
      "  'asked/VBD\n",
      "  'learn/NNP\n",
      "  '/POS\n",
      "  'magical/JJ\n",
      "  'tool/NNP\n",
      "  '/POS\n",
      "  'Statistical/JJ\n",
      "  'Physics/NNS\n",
      "  '/POS\n",
      "  “/NNP\n",
      "  '/POS\n",
      "  'Start/NNP\n",
      "  '/POS\n",
      "  'ensemble/JJ\n",
      "  'theory/NNP\n",
      "  '/POS\n",
      "  ”/NNP\n",
      "  '/POS\n",
      "  'advised/VBD\n",
      "  'Though/IN\n",
      "  'Statistical/JJ\n",
      "  'Physics/NNS\n",
      "  '/POS\n",
      "  'seemed/VBD\n",
      "  'tragedy/NNP\n",
      "  '/POS\n",
      "  'close-up/NNP\n",
      "  '/POS\n",
      "  'Spending/VBG\n",
      "  'several/NNP\n",
      "  '/POS\n",
      "  'textbooks/NNS\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'found/IN\n",
      "  'maze/NNP\n",
      "  '/POS\n",
      "  'understand/NNP\n",
      "  '/POS\n",
      "  'system/NNP\n",
      "  '/POS\n",
      "  'shall/DT\n",
      "  'calculate/NNP\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  'component/NNP\n",
      "  '/POS\n",
      "  ’/NNP\n",
      "  '/POS\n",
      "  'behavior/NNP\n",
      "  '/POS\n",
      "  'This/NNP\n",
      "  '/POS\n",
      "  'commandment/NNP\n",
      "  '/POS\n",
      "  'summarizes/VBZ\n",
      "  '/POS\n",
      "  'physics/NNS\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'learned/VBD\n",
      "  'years/NNS\n",
      "  '/POS\n",
      "  'Science/NNP\n",
      "  '/POS\n",
      "  'Academy/NNP\n",
      "  '/POS\n",
      "  'KSA/NNP\n",
      "  '/POS\n",
      "  'system/NNP\n",
      "  '/POS\n",
      "  'myriad/NNP\n",
      "  '/POS\n",
      "  'particles/NNS\n",
      "  '/POS\n",
      "  'directive/CD\n",
      "  'defied/VBD\n",
      "  'virtual/JJ\n",
      "  'impossibility/NNP\n",
      "  '/POS\n",
      "  'figuring/VBG\n",
      "  'motions/NNS\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  'particle/NNP\n",
      "  '/POS\n",
      "  'physicists/NNS\n",
      "  '/POS\n",
      "  (NP 'construct/NN)\n",
      "  'ensemble/JJ\n",
      "  'macroscopic/NNP\n",
      "  '/POS\n",
      "  'snapshots/NNS\n",
      "  '/POS\n",
      "  'system/NNP\n",
      "  '/POS\n",
      "  'The/NNP\n",
      "  '/POS\n",
      "  'snapshots/NNS\n",
      "  '/POS\n",
      "  'different/NNP\n",
      "  '/POS\n",
      "  'particle/NNP\n",
      "  '/POS\n",
      "  'arrangements/NNS\n",
      "  '/POS\n",
      "  'movements/NNS\n",
      "  '/POS\n",
      "  “/NNP\n",
      "  '/POS\n",
      "  (NP 'collection/NN)\n",
      "  ”/NNP\n",
      "  '/POS\n",
      "  'far/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'understood/NNP\n",
      "  '/POS\n",
      "  'ensemble/JJ\n",
      "  'theory/NNP\n",
      "  '/POS\n",
      "  'understanding/VBG\n",
      "  'movie/NNP\n",
      "  '/POS\n",
      "  'watching/VBG\n",
      "  'preview/NNP\n",
      "  '/POS\n",
      "  'consists/NNS\n",
      "  '/POS\n",
      "  'important/NNP\n",
      "  '/POS\n",
      "  'scenes/NNS\n",
      "  '/POS\n",
      "  'Hypothetically/RB\n",
      "  I/PRP\n",
      "  'analyze/NNP\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  'actor/NNP\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  'line/NNP\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  'would/MD\n",
      "  'actually/RB\n",
      "  '/POS\n",
      "  'grasping/VBG\n",
      "  (NP 'overall/DT 'message/NN)\n",
      "  'film/NNP\n",
      "  '/POS\n",
      "  'In/NNP\n",
      "  '/POS\n",
      "  'short/NNP\n",
      "  '/POS\n",
      "  'theory/NNP\n",
      "  '/POS\n",
      "  'states/NNS\n",
      "  '/POS\n",
      "  'state/NNP\n",
      "  '/POS\n",
      "  'matter/NNP\n",
      "  '/POS\n",
      "  'understood/NNP\n",
      "  '/POS\n",
      "  'without/IN\n",
      "  'knowing/VBG\n",
      "  'movements/NNS\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  'particle/NNP\n",
      "  '/POS\n",
      "  'At/NNP\n",
      "  '/POS\n",
      "  'odds/NNS\n",
      "  '/POS\n",
      "  'existing/VBG\n",
      "  'new/NNP\n",
      "  '/POS\n",
      "  'approach/NNP\n",
      "  '/POS\n",
      "  'refused/VBD\n",
      "  'settle/NNP\n",
      "  '/POS\n",
      "  'well-designed/JJ\n",
      "  'exercise/NNP\n",
      "  '/POS\n",
      "  'problems/NNS\n",
      "  '/POS\n",
      "  'textbooks/NNS\n",
      "  '/POS\n",
      "  'could/MD\n",
      "  'save/NNP\n",
      "  '/POS\n",
      "  'drowning/VBG\n",
      "  'confusion/NNP\n",
      "  '/POS\n",
      "  (NP 'Meanwhile/NN)\n",
      "  'ensemble/JJ\n",
      "  'theory/NNP\n",
      "  '/POS\n",
      "  'suggested/VBD\n",
      "  'possible/JJ\n",
      "  'explanation/NNP\n",
      "  '/POS\n",
      "  'unanswered/VBD\n",
      "  'questions/NNS\n",
      "  '/POS\n",
      "  'KSA/NNP\n",
      "  '/POS\n",
      "  (NP 'Science/NN)\n",
      "  'Fair/NNP\n",
      "  '/POS\n",
      "  'To/NNP\n",
      "  '/POS\n",
      "  'successfully/RB\n",
      "  '/POS\n",
      "  (NP 'manage/NN)\n",
      "  'KSA/NNP\n",
      "  '/POS\n",
      "  ’/NNP\n",
      "  '/POS\n",
      "  'largest/JJS\n",
      "  'international/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'provided/VBD\n",
      "  'detailed/VBD\n",
      "  'instructions/NNS\n",
      "  '/POS\n",
      "  'volunteer/NNP\n",
      "  '/POS\n",
      "  'For/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'assigned/VBD\n",
      "  'volunteers/NNS\n",
      "  '/POS\n",
      "  'specific/NNP\n",
      "  '/POS\n",
      "  'task/NNP\n",
      "  '/POS\n",
      "  'like/IN\n",
      "  'placement/NNP\n",
      "  '/POS\n",
      "  'posters/NNS\n",
      "  '/POS\n",
      "  'strict/NNP\n",
      "  '/POS\n",
      "  (NP 'discussion/NN)\n",
      "  'guidelines/NNS\n",
      "  '/POS\n",
      "  'sessions/NNS\n",
      "  '/POS\n",
      "  'start/NNP\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  (NP 'presentation/NN)\n",
      "  'Despite/NNP\n",
      "  '/POS\n",
      "  'efforts/NNS\n",
      "  '/POS\n",
      "  'trying/VBG\n",
      "  'control/NNP\n",
      "  '/POS\n",
      "  'aspects/NNS\n",
      "  '/POS\n",
      "  'problems/VBZ\n",
      "  '/POS\n",
      "  'emerged/VBD\n",
      "  'volunteers/NNS\n",
      "  '/POS\n",
      "  'starting/VBG\n",
      "  'detailed/VBD\n",
      "  'plan/NNP\n",
      "  '/POS\n",
      "  (NP 'action/NN)\n",
      "  'Initially/RB\n",
      "  I/PRP\n",
      "  'clueless/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'tried/VBD\n",
      "  'understand/NNP\n",
      "  '/POS\n",
      "  'detailed/VBD\n",
      "  'plan/NNP\n",
      "  '/POS\n",
      "  (NP 'execution/NN)\n",
      "  'could/MD\n",
      "  'go/NNP\n",
      "  '/POS\n",
      "  'haywire/NNP\n",
      "  '/POS\n",
      "  'knowledge/NNP\n",
      "  '/POS\n",
      "  'ensemble/JJ\n",
      "  'theory/NNP\n",
      "  '/POS\n",
      "  'deepened/VBD\n",
      "  I/PRP\n",
      "  'began/NNP\n",
      "  '/POS\n",
      "  'fundamental/NNP\n",
      "  '/POS\n",
      "  'problems/NNS\n",
      "  '/POS\n",
      "  'rooted/VBD\n",
      "  'approach/NNP\n",
      "  '/POS\n",
      "  (NP 'Instead/NN)\n",
      "  'micromanagement/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'viewed/VBD\n",
      "  'KSASF/NNP\n",
      "  '/POS\n",
      "  'ensemble/JJ\n",
      "  'bigger/NNP\n",
      "  '/POS\n",
      "  (NP 'picture/NN)\n",
      "  'KSASF/NNP\n",
      "  '/POS\n",
      "  'As/NNP\n",
      "  '/POS\n",
      "  'volunteer/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'brave/NNP\n",
      "  '/POS\n",
      "  'enough/IN\n",
      "  'take/NNP\n",
      "  '/POS\n",
      "  'observe/NNP\n",
      "  '/POS\n",
      "  'created/VBD\n",
      "  'macroscopic/NNP\n",
      "  '/POS\n",
      "  'background/IN\n",
      "  'honors/NNS\n",
      "  '/POS\n",
      "  'essence/NNP\n",
      "  '/POS\n",
      "  'KSASF—the/NNP\n",
      "  '/POS\n",
      "  'exchange/NNP\n",
      "  '/POS\n",
      "  'scientific/NNP\n",
      "  '/POS\n",
      "  'ideas/NNS\n",
      "  '/POS\n",
      "  'second/NNP\n",
      "  '/POS\n",
      "  (NP 'chance/NN)\n",
      "  'volunteer/NNP\n",
      "  '/POS\n",
      "  'KSA/NNP\n",
      "  '/POS\n",
      "  'Youth/NNP\n",
      "  '/POS\n",
      "  (NP 'Science/NN)\n",
      "  'Camp/NNP\n",
      "  '/POS\n",
      "  'mentoring/VBG\n",
      "  'event/NNP\n",
      "  '/POS\n",
      "  'elementary/NNP\n",
      "  '/POS\n",
      "  'middle/NNP\n",
      "  '/POS\n",
      "  'school/NNP\n",
      "  '/POS\n",
      "  'students/NNS\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'envisioned/VBD\n",
      "  'camp/NNP\n",
      "  '/POS\n",
      "  ’/NNP\n",
      "  '/POS\n",
      "  'activities/NNS\n",
      "  '/POS\n",
      "  'perspective/CD\n",
      "  'ensemble/JJ\n",
      "  'event/NNP\n",
      "  '/POS\n",
      "  'camp/NNP\n",
      "  '/POS\n",
      "  'align/NNP\n",
      "  '/POS\n",
      "  'camp/NNP\n",
      "  '/POS\n",
      "  ’/NNP\n",
      "  '/POS\n",
      "  'message—learning/VBG\n",
      "  'science/NNP\n",
      "  '/POS\n",
      "  'inquiries/NNS\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'designed/VBD\n",
      "  'events/NNS\n",
      "  '/POS\n",
      "  'macroscopic/NNP\n",
      "  '/POS\n",
      "  'thinking/VBG\n",
      "  'relevant/NNP\n",
      "  '/POS\n",
      "  'minimizing/VBG\n",
      "  (NP 'structure/NN)\n",
      "  'guidelines/NNS\n",
      "  '/POS\n",
      "  'This/NNP\n",
      "  '/POS\n",
      "  'encouraged/VBD\n",
      "  'volunteers/NNS\n",
      "  '/POS\n",
      "  'proactive/CD\n",
      "  'fully/RB\n",
      "  '/POS\n",
      "  'showing/VBG\n",
      "  'expertise/NNP\n",
      "  '/POS\n",
      "  'dynamic/NNP\n",
      "  '/POS\n",
      "  ‘/NNP\n",
      "  '/POS\n",
      "  'open/NNP\n",
      "  '/POS\n",
      "  (NP 'discussion/NN)\n",
      "  'sessions/NNS\n",
      "  ’/NNP\n",
      "  '/POS\n",
      "  'Compared/VBD\n",
      "  'KSASF/NNP\n",
      "  '/POS\n",
      "  'camp/NNP\n",
      "  '/POS\n",
      "  'unpredictable/JJ\n",
      "  'micro-level/JJ\n",
      "  'interactions—one/CD\n",
      "  'topics/NNS\n",
      "  '/POS\n",
      "  'Does/NNS\n",
      "  '/POS\n",
      "  (NP 'science/NN)\n",
      "  'make/NNP\n",
      "  '/POS\n",
      "  'world/NNP\n",
      "  '/POS\n",
      "  'better/NNP\n",
      "  '/POS\n",
      "  'initiated/VBD\n",
      "  'casual/JJ\n",
      "  'conversation/NNP\n",
      "  '/POS\n",
      "  'volunteer/NNP\n",
      "  '/POS\n",
      "  'participants/NNS\n",
      "  '/POS\n",
      "  'Feeling/VBG\n",
      "  'power/NNP\n",
      "  '/POS\n",
      "  'ensemble/JJ\n",
      "  'theory/NNP\n",
      "  '/POS\n",
      "  'real-life/JJ\n",
      "  'exercise/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'could/MD\n",
      "  'embrace/NNP\n",
      "  '/POS\n",
      "  'idea/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'account/NNP\n",
      "  '/POS\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  (NP 'interaction/NN)\n",
      "  'every/NNP\n",
      "  '/POS\n",
      "  'Regardless/NNP\n",
      "  '/POS\n",
      "  I/PRP\n",
      "  'believe/NNP\n",
      "  '/POS\n",
      "  'may/NNP\n",
      "  '/POS\n",
      "  'find/IN\n",
      "  'ways/NNS\n",
      "  '/POS\n",
      "  'grasp/NNP\n",
      "  '/POS\n",
      "  'complexity/NNP\n",
      "  '/POS\n",
      "  'world/NNP\n",
      "  '/POS\n",
      "  'embracing/VBG\n",
      "  'limitations/NNS\n",
      "  '/POS\n",
      "  'humbly/RB\n",
      "  'accepting/VBG\n",
      "  'uncontrollable/JJ\n",
      "  'versatility/NNP\n",
      "  '/POS\n",
      "  'From/IN\n",
      "  ’/NNP\n",
      "  '/POS\n",
      "  'viewpoint/NNP\n",
      "  '/POS\n",
      "  'may/NNP\n",
      "  '/POS\n",
      "  'sound/IN\n",
      "  'ironic/NNP\n",
      "  '/POS\n",
      "  'Still/NNP\n",
      "  '/POS\n",
      "  'ensemble/JJ\n",
      "  'theory/NNP\n",
      "  '/POS\n",
      "  'taught/NNP\n",
      "  '/POS\n",
      "  'gaze/NNP\n",
      "  '/POS\n",
      "  'bigger/NNP\n",
      "  '/POS\n",
      "  (NP 'picture/NN)\n",
      "  'observe/NNP\n",
      "  '/POS\n",
      "  'frames/NNS\n",
      "  '/POS\n",
      "  'connect/NNP\n",
      "  '/POS\n",
      "  'see/NNP\n",
      "  '/POS\n",
      "  'meaning/VBG\n",
      "  'embedded/VBD\n",
      "  'behind/IN\n",
      "  'complexity/NNP\n",
      "  '/POS\n",
      "  'During/VBG\n",
      "  'Statistical/NNP\n",
      "  '/POS\n",
      "  'Physics/NNS\n",
      "  '/POS\n",
      "  'PH/NNP\n",
      "  '/POS\n",
      "  'class/NNP\n",
      "  '/POS\n",
      "  'KAIST/NNP\n",
      "  '/POS\n",
      "  'professor/NNP\n",
      "  '/POS\n",
      "  'asked/VBD\n",
      "  I/PRP\n",
      "  'knew/NNP\n",
      "  '/POS\n",
      "  'concept/IN\n",
      "  'ensemble/JJ\n",
      "  'After/NNP\n",
      "  '/POS\n",
      "  'sharing/VBG\n",
      "  'experiences/NNS\n",
      "  '/POS\n",
      "  'warmly/NNP\n",
      "  '/POS\n",
      "  'smiled/VBD\n",
      "  'said/NNP\n",
      "  '/POS\n",
      "  'Good/NNP\n",
      "  '/POS\n",
      "  'start/NNP\n",
      "  '/POS\n",
      "  ]/NNP\n",
      "  '/POS\n",
      "  (NP ]/NN))\n"
     ]
    }
   ],
   "source": [
    "reg_exp = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "rp = nltk.RegexpParser(reg_exp)\n",
    "result = rp.parse(result.tags)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 개발하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가자료 : https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[\"Python\", \"YUNDAEHEE\", \"076923\"]\n",
    "\n",
    "file=open('textfile.txt','w')\n",
    "\n",
    "file.write(\"START\\n\")\n",
    "\n",
    "for i in range(3):\n",
    "    file.write('%s\\n' %L[i])\n",
    "\n",
    "file.write(\"END\")\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START', 'Python', 'YUNDAEHEE', '076923', 'END']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached https://files.pythonhosted.org/packages/1e/27/6fdcddfbce1963989eb527f0ba4749829509c0172c275806cffd5a7e1776/gensim-3.8.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.11.3 in /anaconda3/lib/python3.6/site-packages (from gensim) (1.16.4)\n",
      "Collecting scipy>=0.18.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/94/cd76305a69fff844e83655ed7b254835df4eddd5fc0e2d0eb2914501b36e/scipy-1.4.1-cp36-cp36m-macosx_10_6_intel.whl (28.5MB)\n",
      "\u001b[K     |████████████████████████████████| 28.5MB 4.9MB/s eta 0:00:01     |█████████████████████▏          | 18.9MB 8.3MB/s eta 0:00:02     |█████████████████████▌          | 19.1MB 8.3MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/14/47cf88d290e4681be35f3b6e8889ba26ed809a0ba14336dc8ae46ffcfda8/smart_open-1.10.0.tar.gz (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 4.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /Users/kimkwangil/.local/lib/python3.6/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: requests in /anaconda3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\n",
      "Collecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b5/27c94221d240b9df187b2623243b22db914238a651549defa59ffbfed7b4/boto3-1.12.24-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-storage (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/67/80761781f813ffbf8bc1db7270b6d23de7a96468da4601de3bf2e5e1d829/google_cloud_storage-1.26.0-py2.py3-none-any.whl (75kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 9.6MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/43/1e939e1fcd87b827fe192d0c9fc25b48c5b3368902bfb913de7754b0dc03/jmespath-0.9.5-py2.py3-none-any.whl\n",
      "Collecting botocore<1.16.0,>=1.15.24 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/aa/001b6c820b44dd5fcf7361ddad9be4f1cbc4609f5487583f74bcf1b93001/botocore-1.15.24-py2.py3-none-any.whl (6.0MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0MB 6.5MB/s eta 0:00:01     |██████████████▊                 | 2.7MB 1.4MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.6MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-auth<2.0dev,>=1.11.0 (from google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/f8/2da482a6165ef3f28d52faf8c2ca31628129a84a294033eb399ef500e265/google_auth-1.11.3-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 4.5MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.2.0 (from google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /anaconda3/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.24->boto3->smart-open>=1.8.1->gensim) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /anaconda3/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.24->boto3->smart-open>=1.8.1->gensim) (2.7.5)\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.8.1->gensim) (40.6.3)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.8.1->gensim) (0.2.2)\n",
      "Collecting google-api-core<2.0.0dev,>=1.16.0 (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /anaconda3/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.8.1->gensim) (0.4.4)\n",
      "Requirement already satisfied: pytz in /anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim) (2018.7)\n",
      "Collecting protobuf>=3.4.0 (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/65/3ac73d6a9f31de4b45ebff6885e9a4ccd16eccb63764dd406140d337fabd/protobuf-3.11.3-cp36-cp36m-macosx_10_9_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 38kB/s eta 0:00:012\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/46/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf/googleapis-common-protos-1.51.0.tar.gz\n",
      "Building wheels for collected packages: smart-open, googleapis-common-protos\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/kimkwangil/Library/Caches/pip/wheels/f8/00/d4/a6b8b6aa241459103d19e757f96645549dd562d5b5de653f44\n",
      "  Building wheel for googleapis-common-protos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/kimkwangil/Library/Caches/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\n",
      "Successfully built smart-open googleapis-common-protos\n",
      "Installing collected packages: scipy, jmespath, botocore, s3transfer, boto3, rsa, cachetools, google-auth, protobuf, googleapis-common-protos, google-api-core, google-cloud-core, google-resumable-media, google-cloud-storage, smart-open, gensim\n",
      "Successfully installed boto3-1.12.24 botocore-1.15.24 cachetools-4.0.0 gensim-3.8.1 google-api-core-1.16.0 google-auth-1.11.3 google-cloud-core-1.3.0 google-cloud-storage-1.26.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 jmespath-0.9.5 protobuf-3.11.3 rsa-4.0 s3transfer-0.3.3 scipy-1.4.1 smart-open-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import nltk #형태소 분석기 가져오기\n",
    "import string #특수문자 \n",
    "import warnings#경고알림문자 제거\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) #경고알림 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-89181c3ffb71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#함수를 불러오는 메인코드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0minput_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"UniversityMajor/01_Harvard/HarvardEssays.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mSW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storwords.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-89181c3ffb71>\u001b[0m in \u001b[0;36mread_documents\u001b[0;34m(input_file_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtemp_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_corpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "def read_documents(input_file_name):\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(input_file_name, 'rb') as f:\n",
    "        temp_corpus = pickle.load(f)\n",
    "    \n",
    "    for page in temp_corpus:\n",
    "        corpus += page\n",
    "        \n",
    "    return corpus\n",
    "\n",
    "def text_cleaning(doc):\n",
    "    cleaned_docs = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        temp_doc = re.sub(\"\", doc)\n",
    "        cleaned_docs.append(temp_doc)\n",
    "        \n",
    "    return cleaned_docs\n",
    "\n",
    "def define_stopwords(path):\n",
    "    SW = set()\n",
    "    for i in string.punctuation:\n",
    "        SW.add(i)\n",
    "    with open(path) as f:\n",
    "        for word in f:\n",
    "            SW.add(word)\n",
    "    return SW\n",
    "\n",
    "def text_tokenizing(corpus, tokenizer):\n",
    "    token_corpus = []\n",
    "    \n",
    "    if tokenizer == \"none\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = nltk.nouns(corpus[n])\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "            \n",
    "    elif tokenized == \"morph\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = nltk.nouns(corpus[n])\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "            \n",
    "    elif tokenized == \"word\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = corpus[n].split()\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "\n",
    "                \n",
    "    return token_corpus\n",
    "\n",
    "#함수를 불러오는 메인코드\n",
    "input_file_name = \"UniversityMajor/01_Harvard/HarvardEssays.txt\"\n",
    "documents = read_documents(input_file_name)\n",
    "SW = define_stopwords(\"storwords.txt\")\n",
    "cleaned_text = text_cleaning(documents)\n",
    "tokenized_text = text_tokenizing(cleaned_text, tokenizer=\"noun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d3ab8c71ee33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UniversityMajor/01_Harvard/HarvardEssays.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "dataset = pandas.read_csv('UniversityMajor/01_Harvard/HarvardEssays.txt', delimiter='\\t')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
